{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ywSRtNI4s5h"
   },
   "source": [
    "# 0.) Import the Credit Card Fraud Data From CCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nsG1QV154GYZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KJQfo8mz43Kz"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fraudTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "mKWSRv-q98wE",
    "outputId": "29838bae-3f83-4216-f0da-f7ea7ee6ee69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-21 12:14:25</td>\n",
       "      <td>2291163933867244</td>\n",
       "      <td>fraud_Kirlin and Sons</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>2.86</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>Elliott</td>\n",
       "      <td>M</td>\n",
       "      <td>351 Darlene Green</td>\n",
       "      <td>...</td>\n",
       "      <td>33.9659</td>\n",
       "      <td>-80.9355</td>\n",
       "      <td>333497</td>\n",
       "      <td>Mechanical engineer</td>\n",
       "      <td>1968-03-19</td>\n",
       "      <td>2da90c7d74bd46a0caf3777415b3ebd3</td>\n",
       "      <td>1371816865</td>\n",
       "      <td>33.986391</td>\n",
       "      <td>-81.200714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-21 12:14:33</td>\n",
       "      <td>3573030041201292</td>\n",
       "      <td>fraud_Sporer-Keebler</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>29.84</td>\n",
       "      <td>Joanne</td>\n",
       "      <td>Williams</td>\n",
       "      <td>F</td>\n",
       "      <td>3638 Marsh Union</td>\n",
       "      <td>...</td>\n",
       "      <td>40.3207</td>\n",
       "      <td>-110.4360</td>\n",
       "      <td>302</td>\n",
       "      <td>Sales professional, IT</td>\n",
       "      <td>1990-01-17</td>\n",
       "      <td>324cc204407e99f51b0d6ca0055005e7</td>\n",
       "      <td>1371816873</td>\n",
       "      <td>39.450498</td>\n",
       "      <td>-109.960431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-06-21 12:14:53</td>\n",
       "      <td>3598215285024754</td>\n",
       "      <td>fraud_Swaniawski, Nitzsche and Welch</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>41.28</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Lopez</td>\n",
       "      <td>F</td>\n",
       "      <td>9333 Valentine Point</td>\n",
       "      <td>...</td>\n",
       "      <td>40.6729</td>\n",
       "      <td>-73.5365</td>\n",
       "      <td>34496</td>\n",
       "      <td>Librarian, public</td>\n",
       "      <td>1970-10-21</td>\n",
       "      <td>c81755dbbbea9d5c77f094348a7579be</td>\n",
       "      <td>1371816893</td>\n",
       "      <td>40.495810</td>\n",
       "      <td>-74.196111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-06-21 12:15:15</td>\n",
       "      <td>3591919803438423</td>\n",
       "      <td>fraud_Haley Group</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>60.05</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Williams</td>\n",
       "      <td>M</td>\n",
       "      <td>32941 Krystal Mill Apt. 552</td>\n",
       "      <td>...</td>\n",
       "      <td>28.5697</td>\n",
       "      <td>-80.8191</td>\n",
       "      <td>54767</td>\n",
       "      <td>Set designer</td>\n",
       "      <td>1987-07-25</td>\n",
       "      <td>2159175b9efe66dc301f149d3d5abf8c</td>\n",
       "      <td>1371816915</td>\n",
       "      <td>28.812398</td>\n",
       "      <td>-80.883061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-21 12:15:17</td>\n",
       "      <td>3526826139003047</td>\n",
       "      <td>fraud_Johnston-Casper</td>\n",
       "      <td>travel</td>\n",
       "      <td>3.19</td>\n",
       "      <td>Nathan</td>\n",
       "      <td>Massey</td>\n",
       "      <td>M</td>\n",
       "      <td>5783 Evan Roads Apt. 465</td>\n",
       "      <td>...</td>\n",
       "      <td>44.2529</td>\n",
       "      <td>-85.0170</td>\n",
       "      <td>1126</td>\n",
       "      <td>Furniture designer</td>\n",
       "      <td>1955-07-06</td>\n",
       "      <td>57ff021bd3f328f8738bb535c302a31b</td>\n",
       "      <td>1371816917</td>\n",
       "      <td>44.959148</td>\n",
       "      <td>-85.884734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2020-06-21 12:14:25  2291163933867244   \n",
       "1           1   2020-06-21 12:14:33  3573030041201292   \n",
       "2           2   2020-06-21 12:14:53  3598215285024754   \n",
       "3           3   2020-06-21 12:15:15  3591919803438423   \n",
       "4           4   2020-06-21 12:15:17  3526826139003047   \n",
       "\n",
       "                               merchant        category    amt   first  \\\n",
       "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
       "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
       "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
       "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
       "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
       "\n",
       "       last gender                       street  ...      lat      long  \\\n",
       "0   Elliott      M            351 Darlene Green  ...  33.9659  -80.9355   \n",
       "1  Williams      F             3638 Marsh Union  ...  40.3207 -110.4360   \n",
       "2     Lopez      F         9333 Valentine Point  ...  40.6729  -73.5365   \n",
       "3  Williams      M  32941 Krystal Mill Apt. 552  ...  28.5697  -80.8191   \n",
       "4    Massey      M     5783 Evan Roads Apt. 465  ...  44.2529  -85.0170   \n",
       "\n",
       "   city_pop                     job         dob  \\\n",
       "0    333497     Mechanical engineer  1968-03-19   \n",
       "1       302  Sales professional, IT  1990-01-17   \n",
       "2     34496       Librarian, public  1970-10-21   \n",
       "3     54767            Set designer  1987-07-25   \n",
       "4      1126      Furniture designer  1955-07-06   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
       "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
       "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
       "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
       "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_YuJa4IFKda",
    "outputId": "7e387d76-2dd6-472c-d598-5994ef2b9fda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/2p2qsjgx4yd0cjtw95rvsjwh0000gn/T/ipykernel_97271/1789677364.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_select[\"trans_date_trans_time\"] = pd.to_datetime(df_select[\"trans_date_trans_time\"])\n",
      "/var/folders/l4/2p2qsjgx4yd0cjtw95rvsjwh0000gn/T/ipykernel_97271/1789677364.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_select[\"time_var\"] = [i.second for i in df_select[\"trans_date_trans_time\"]]\n"
     ]
    }
   ],
   "source": [
    "df_select = df[[\"trans_date_trans_time\", \"category\", \"amt\", \"city_pop\", \"is_fraud\"]]\n",
    "\n",
    "df_select[\"trans_date_trans_time\"] = pd.to_datetime(df_select[\"trans_date_trans_time\"])\n",
    "df_select[\"time_var\"] = [i.second for i in df_select[\"trans_date_trans_time\"]]\n",
    "\n",
    "X = pd.get_dummies(df_select, [\"category\"]).drop([\"trans_date_trans_time\", \"is_fraud\"], axis = 1)\n",
    "y = df[[\"is_fraud\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VsnpGe9-B3p"
   },
   "source": [
    "# 1.) Use scikit learn preprocessing to split the data into 70/30 in out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1tpCDMW198ym"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FZvnpERK981d"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>time_var</th>\n",
       "      <th>category_entertainment</th>\n",
       "      <th>category_food_dining</th>\n",
       "      <th>category_gas_transport</th>\n",
       "      <th>category_grocery_net</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>category_shopping_pos</th>\n",
       "      <th>category_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223306</th>\n",
       "      <td>37.07</td>\n",
       "      <td>2518</td>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243830</th>\n",
       "      <td>2.34</td>\n",
       "      <td>1679</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515232</th>\n",
       "      <td>44.40</td>\n",
       "      <td>16163</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139547</th>\n",
       "      <td>62.38</td>\n",
       "      <td>3224</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315221</th>\n",
       "      <td>73.49</td>\n",
       "      <td>551</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499572</th>\n",
       "      <td>43.53</td>\n",
       "      <td>2443</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287393</th>\n",
       "      <td>62.34</td>\n",
       "      <td>18408</td>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316677</th>\n",
       "      <td>65.11</td>\n",
       "      <td>1725</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440020</th>\n",
       "      <td>71.63</td>\n",
       "      <td>67858</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20621</th>\n",
       "      <td>108.37</td>\n",
       "      <td>18128</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389003 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           amt  city_pop  time_var  category_entertainment  \\\n",
       "223306   37.07      2518        47                   False   \n",
       "243830    2.34      1679        11                   False   \n",
       "515232   44.40     16163        52                   False   \n",
       "139547   62.38      3224        17                   False   \n",
       "315221   73.49       551        23                   False   \n",
       "...        ...       ...       ...                     ...   \n",
       "499572   43.53      2443         2                   False   \n",
       "287393   62.34     18408        45                    True   \n",
       "316677   65.11      1725        18                   False   \n",
       "440020   71.63     67858        14                   False   \n",
       "20621   108.37     18128        42                   False   \n",
       "\n",
       "        category_food_dining  category_gas_transport  category_grocery_net  \\\n",
       "223306                 False                   False                 False   \n",
       "243830                  True                   False                 False   \n",
       "515232                  True                   False                 False   \n",
       "139547                 False                    True                 False   \n",
       "315221                 False                   False                 False   \n",
       "...                      ...                     ...                   ...   \n",
       "499572                 False                   False                 False   \n",
       "287393                 False                   False                 False   \n",
       "316677                 False                   False                 False   \n",
       "440020                 False                   False                 False   \n",
       "20621                  False                   False                 False   \n",
       "\n",
       "        category_grocery_pos  category_health_fitness  category_home  \\\n",
       "223306                 False                    False          False   \n",
       "243830                 False                    False          False   \n",
       "515232                 False                    False          False   \n",
       "139547                 False                    False          False   \n",
       "315221                  True                    False          False   \n",
       "...                      ...                      ...            ...   \n",
       "499572                 False                    False          False   \n",
       "287393                 False                    False          False   \n",
       "316677                 False                    False          False   \n",
       "440020                 False                    False          False   \n",
       "20621                  False                    False          False   \n",
       "\n",
       "        category_kids_pets  category_misc_net  category_misc_pos  \\\n",
       "223306                True              False              False   \n",
       "243830               False              False              False   \n",
       "515232               False              False              False   \n",
       "139547               False              False              False   \n",
       "315221               False              False              False   \n",
       "...                    ...                ...                ...   \n",
       "499572               False              False              False   \n",
       "287393               False              False              False   \n",
       "316677                True              False              False   \n",
       "440020               False              False              False   \n",
       "20621                False              False              False   \n",
       "\n",
       "        category_personal_care  category_shopping_net  category_shopping_pos  \\\n",
       "223306                   False                  False                  False   \n",
       "243830                   False                  False                  False   \n",
       "515232                   False                  False                  False   \n",
       "139547                   False                  False                  False   \n",
       "315221                   False                  False                  False   \n",
       "...                        ...                    ...                    ...   \n",
       "499572                    True                  False                  False   \n",
       "287393                   False                  False                  False   \n",
       "316677                   False                  False                  False   \n",
       "440020                    True                  False                  False   \n",
       "20621                    False                   True                  False   \n",
       "\n",
       "        category_travel  \n",
       "223306            False  \n",
       "243830            False  \n",
       "515232            False  \n",
       "139547            False  \n",
       "315221            False  \n",
       "...                 ...  \n",
       "499572            False  \n",
       "287393            False  \n",
       "316677            False  \n",
       "440020            False  \n",
       "20621             False  \n",
       "\n",
       "[389003 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JvCzIdgO983i"
   },
   "outputs": [],
   "source": [
    "X_test, X_holdout, y_test, y_holdout = train_test_split(X_test, y_test, test_size = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f7APv9N3986a"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_holdout = scaler.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbkpNPyN-Gnk"
   },
   "source": [
    "# 2.) Make three sets of training data (Oversample, Undersample and SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gTTVciVkqopH"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gG88uxbiV4lZ"
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "over_X, over_y = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "under_X, under_y = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "smote = SMOTE()\n",
    "smote_X, smote_y = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNu6ysyV988v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifsNzHvOlpdf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQE60rwv98_F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkfqhq4J99A6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GvhU8UN99DR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7n_cImg99F3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIJx2jvD-KEI"
   },
   "source": [
    "# 3.) Train three logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QhVMq92zvz4s"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NvwomEoaGAgN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "over_log = LogisticRegression().fit(over_X, over_y)\n",
    "\n",
    "under_log = LogisticRegression().fit(under_X, under_y)\n",
    "\n",
    "smote_log = LogisticRegression().fit(smote_X, smote_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwXa-bvX99Id"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VG0_5eniGH9P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vj5uNeAr99LE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwLCfa9599RE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLIndmpE99Tq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wzri7XuG-OXp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeurmqI4-OoC"
   },
   "source": [
    "# 4.) Test the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tpSsOC0xsKs",
    "outputId": "fee6e3f0-6c06-489e-90da-59237e609bca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9178003311019938"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwq8KTmsXhFY",
    "outputId": "7c01f959-58d8-44c6-e955-39fe84168d8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108064013052136"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjgQ8BQM99WR",
    "outputId": "a4f3fa30-e8f3-43f4-b562-959b200488e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9178963026944025"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "IF_H74Ht-RIL"
   },
   "outputs": [],
   "source": [
    "# We see SMOTE performing with higher accuracy but is ACCURACY really the best measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udwK0byx-RLA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6isBwtmL-R4p"
   },
   "source": [
    "# 5.) Which performed best in Out of Sample metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "9fwAhujT-RN4"
   },
   "outputs": [],
   "source": [
    "# Sensitivity here in credit fraud is more important as seen from last class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "POIuy3rH-RQv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "e42UoedMK6eq"
   },
   "outputs": [],
   "source": [
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mc_RyrHK6hX",
    "outputId": "408bb243-3c83-4337-97f5-21f57718360f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76273,  6772],\n",
       "       [   80,   233]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = over_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xT6gNjLuK6jS",
    "outputId": "2ed847ca-c7a5-414b-d45a-2e7acadfc9d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over Sample Sensitivity :  0.744408945686901\n"
     ]
    }
   ],
   "source": [
    "print(\"Over Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTHhw9P1K6lY",
    "outputId": "cadf0e8b-2b60-4ac8-fa81-275d3fab8c6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75689,  7356],\n",
       "       [   79,   234]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = under_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g14fgEkT-RTV",
    "outputId": "72b0902b-c2f5-46c7-c49c-83126c75c94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under Sample Sensitivity :  0.7476038338658147\n"
     ]
    }
   ],
   "source": [
    "print(\"Under Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_iZ217d8LAR0",
    "outputId": "6d498a8f-bdd9-445d-97cc-6e4eec82574b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76281,  6764],\n",
       "       [   80,   233]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = smote_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5bfByOALAUk",
    "outputId": "a7071ed7-f896-4825-90f4-612a0603697a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Sample Sensitivity :  0.744408945686901\n"
     ]
    }
   ],
   "source": [
    "print(\"SMOTE Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gAU63Wc-RWN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQa3sanl-XUk"
   },
   "source": [
    "# 6.) Pick two features and plot the two classes before and after SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MDSBmS_usbeJ"
   },
   "outputs": [],
   "source": [
    "raw_temp = pd.concat([pd.DataFrame(X_train), pd.DataFrame(y_train)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9QA-y6HCslBR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.214237</td>\n",
       "      <td>-0.285189</td>\n",
       "      <td>1.012773</td>\n",
       "      <td>-0.278751</td>\n",
       "      <td>-0.274627</td>\n",
       "      <td>-0.336593</td>\n",
       "      <td>-0.191212</td>\n",
       "      <td>-0.322397</td>\n",
       "      <td>-0.265826</td>\n",
       "      <td>-0.322066</td>\n",
       "      <td>3.229577</td>\n",
       "      <td>-0.22789</td>\n",
       "      <td>-0.257957</td>\n",
       "      <td>-0.275508</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>-0.314805</td>\n",
       "      <td>-0.180311</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.445697</td>\n",
       "      <td>-0.287971</td>\n",
       "      <td>-1.068059</td>\n",
       "      <td>-0.278751</td>\n",
       "      <td>3.641307</td>\n",
       "      <td>-0.336593</td>\n",
       "      <td>-0.191212</td>\n",
       "      <td>-0.322397</td>\n",
       "      <td>-0.265826</td>\n",
       "      <td>-0.322066</td>\n",
       "      <td>-0.309638</td>\n",
       "      <td>-0.22789</td>\n",
       "      <td>-0.257957</td>\n",
       "      <td>-0.275508</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>-0.314805</td>\n",
       "      <td>-0.180311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.165386</td>\n",
       "      <td>-0.239943</td>\n",
       "      <td>1.301778</td>\n",
       "      <td>-0.278751</td>\n",
       "      <td>3.641307</td>\n",
       "      <td>-0.336593</td>\n",
       "      <td>-0.191212</td>\n",
       "      <td>-0.322397</td>\n",
       "      <td>-0.265826</td>\n",
       "      <td>-0.322066</td>\n",
       "      <td>-0.309638</td>\n",
       "      <td>-0.22789</td>\n",
       "      <td>-0.257957</td>\n",
       "      <td>-0.275508</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>-0.314805</td>\n",
       "      <td>-0.180311</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.045558</td>\n",
       "      <td>-0.282848</td>\n",
       "      <td>-0.721254</td>\n",
       "      <td>-0.278751</td>\n",
       "      <td>-0.274627</td>\n",
       "      <td>2.970948</td>\n",
       "      <td>-0.191212</td>\n",
       "      <td>-0.322397</td>\n",
       "      <td>-0.265826</td>\n",
       "      <td>-0.322066</td>\n",
       "      <td>-0.309638</td>\n",
       "      <td>-0.22789</td>\n",
       "      <td>-0.257957</td>\n",
       "      <td>-0.275508</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>-0.314805</td>\n",
       "      <td>-0.180311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028485</td>\n",
       "      <td>-0.291711</td>\n",
       "      <td>-0.374448</td>\n",
       "      <td>-0.278751</td>\n",
       "      <td>-0.274627</td>\n",
       "      <td>-0.336593</td>\n",
       "      <td>-0.191212</td>\n",
       "      <td>3.101766</td>\n",
       "      <td>-0.265826</td>\n",
       "      <td>-0.322066</td>\n",
       "      <td>-0.309638</td>\n",
       "      <td>-0.22789</td>\n",
       "      <td>-0.257957</td>\n",
       "      <td>-0.275508</td>\n",
       "      <td>-0.285052</td>\n",
       "      <td>-0.314805</td>\n",
       "      <td>-0.180311</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458779</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431549</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499572</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440020</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505564 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.214237 -0.285189  1.012773 -0.278751 -0.274627 -0.336593 -0.191212   \n",
       "1      -0.445697 -0.287971 -1.068059 -0.278751  3.641307 -0.336593 -0.191212   \n",
       "2      -0.165386 -0.239943  1.301778 -0.278751  3.641307 -0.336593 -0.191212   \n",
       "3      -0.045558 -0.282848 -0.721254 -0.278751 -0.274627  2.970948 -0.191212   \n",
       "4       0.028485 -0.291711 -0.374448 -0.278751 -0.274627 -0.336593 -0.191212   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "458779       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "431549       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "418131       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "499572       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "440020       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "               7         8         9        10       11        12        13  \\\n",
       "0      -0.322397 -0.265826 -0.322066  3.229577 -0.22789 -0.257957 -0.275508   \n",
       "1      -0.322397 -0.265826 -0.322066 -0.309638 -0.22789 -0.257957 -0.275508   \n",
       "2      -0.322397 -0.265826 -0.322066 -0.309638 -0.22789 -0.257957 -0.275508   \n",
       "3      -0.322397 -0.265826 -0.322066 -0.309638 -0.22789 -0.257957 -0.275508   \n",
       "4       3.101766 -0.265826 -0.322066 -0.309638 -0.22789 -0.257957 -0.275508   \n",
       "...          ...       ...       ...       ...      ...       ...       ...   \n",
       "458779       NaN       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "431549       NaN       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "418131       NaN       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "499572       NaN       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "440020       NaN       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "\n",
       "              14        15        16  is_fraud  \n",
       "0      -0.285052 -0.314805 -0.180311       0.0  \n",
       "1      -0.285052 -0.314805 -0.180311       NaN  \n",
       "2      -0.285052 -0.314805 -0.180311       0.0  \n",
       "3      -0.285052 -0.314805 -0.180311       NaN  \n",
       "4      -0.285052 -0.314805 -0.180311       0.0  \n",
       "...          ...       ...       ...       ...  \n",
       "458779       NaN       NaN       NaN       0.0  \n",
       "431549       NaN       NaN       NaN       0.0  \n",
       "418131       NaN       NaN       NaN       0.0  \n",
       "499572       NaN       NaN       NaN       0.0  \n",
       "440020       NaN       NaN       NaN       0.0  \n",
       "\n",
       "[505564 rows x 18 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "vVaHpqf9wHj7",
    "outputId": "105a15c4-f26c-4210-f97c-4b4c3112344e"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'amt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'amt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 0][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 0][\"city_pop\"])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(raw_temp[raw_temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_fraud\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamt\u001b[39m\u001b[38;5;124m\"\u001b[39m], raw_temp[raw_temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_fraud\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity_pop\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFraud\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Fraud\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'amt'"
     ]
    }
   ],
   "source": [
    "#plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 0][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 0][\"city_pop\"])\n",
    "\n",
    "plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 1][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 1][\"city_pop\"])\n",
    "plt.legend([\"Fraud\", \"Not Fraud\"])\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Population\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "YphNDj12aFhP"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([smote_X, smote_y], axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    383\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[1;32m    384\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m    385\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[1;32m    386\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[1;32m    387\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[1;32m    388\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[1;32m    389\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:446\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n\u001b[1;32m    447\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:487\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    483\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    484\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         )\n\u001b[0;32m--> 487\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    489\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_temp = pd.concat([smote_X, smote_y], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "G-MUv66T-RZE",
    "outputId": "a845731d-5a52-4480-d5eb-8dd58de8c3ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHACAYAAABeV0mSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiIklEQVR4nO3deXwV9b3/8dfMWXOyh5AFCBBWQbbIZkRbtSiiP712uVpXQNtbrTu3rdIKaqtCa7XYurVeFK11bZXWDbW44BJBNpWyKLKEJSFAyJ6cbeb3R+RoJEASTnKSk/fz8TgPyJzvzPnMJDnnnZnvfL+Gbds2IiIiInHCjHUBIiIiItGkcCMiIiJxReFGRERE4orCjYiIiMQVhRsRERGJKwo3IiIiElcUbkRERCSuKNyIiIhIXFG4ERERkbiicCMiIiJxpVuHm6VLl3L22WfTq1cvDMNg0aJFrd6Gbdv8/ve/Z8iQIXg8Hnr37s0dd9wR/WJFRESkRZyxLiCWamtrGT16NJdddhnf+9732rSN6667jtdff53f//73jBw5kvLycsrLy6NcqYiIiLSUoYkzGxmGwQsvvMC5554bWeb3+/nVr37FU089RUVFBSNGjOC3v/0tJ598MgDr169n1KhRrF27lqFDh8amcBEREWmiW1+WOpKrr76aoqIinn76aT755BP++7//mzPOOIPPP/8cgBdffJEBAwbw0ksvkZ+fT//+/fnRj36kMzciIiIxpHBzCMXFxTz66KM899xznHTSSQwcOJCf/exnnHjiiTz66KMAbN68mW3btvHcc8/x+OOPs3DhQlauXMkPfvCDGFcvIiLSfXXrPjeH8+mnnxIOhxkyZEiT5X6/nx49egBgWRZ+v5/HH3880m7BggWMHTuWjRs36lKViIhIDCjcHEJNTQ0Oh4OVK1ficDiaPJeUlARAbm4uTqezSQAaNmwY0HjmR+FGRESk4yncHEJBQQHhcJiysjJOOumkZttMmjSJUCjEF198wcCBAwH47LPPAOjXr1+H1SoiIiJf6dZ3S9XU1LBp0yagMczcc889nHLKKWRkZNC3b18uvvhi3n//fe6++24KCgrYs2cPS5YsYdSoUZx11llYlsX48eNJSkpi/vz5WJbFVVddRUpKCq+//nqM905ERKR76tbh5u233+aUU045aPm0adNYuHAhwWCQ22+/nccff5ydO3eSmZnJ8ccfz2233cbIkSMB2LVrF9dccw2vv/46iYmJTJ06lbvvvpuMjIyO3h0RERGhm4cbERERiT+6FVxERETiisKNiIiIxJVud7eUZVns2rWL5ORkDMOIdTkiIiLSArZtU11dTa9evTDNw5+b6XbhZteuXeTl5cW6DBEREWmD7du306dPn8O26XbhJjk5GWg8OCkpKTGuRkRERFqiqqqKvLy8yOf44XS7cHPgUlRKSorCjYiISBfTki4l6lAsIiIicUXhRkREROKKwo2IiIjElW7X50ZEROKLZVkEAoFYlyFR4Ha7j3ibd0so3IiISJcVCATYsmULlmXFuhSJAtM0yc/Px+12H9V2Yhpuli5dyl133cXKlSspKSnhhRde4Nxzzz3sOn6/n1//+tc88cQTlJaWkpuby5w5c7jssss6pmgREekUbNumpKQEh8NBXl5eVP7il9g5MMhuSUkJffv2PaqBdmMabmpraxk9ejSXXXYZ3/ve91q0znnnncfu3btZsGABgwYNoqSkRIldRKQbCoVC1NXV0atXL3w+X6zLkSjo2bMnu3btIhQK4XK52rydmIabqVOnMnXq1Ba3X7x4Me+88w6bN28mIyMDgP79+7dTdSIi0pmFw2GAo76EIZ3Hge9lOBw+qnDTpc7h/etf/2LcuHH87ne/o3fv3gwZMoSf/exn1NfXH3Idv99PVVVVk4eIiMQPzRMYP6L1vexSHYo3b97Me++9h9fr5YUXXmDv3r389Kc/Zd++fTz66KPNrjN37lxuu+22DqsxELL4a9FWtuyrxbZtUr1uDBNSPS4qGgLYNlTWBymtrKe02k8wZJHscTI0J5lUr5tdVQ3sq2kgweUgK8VDcoKL3ZV+AHqnJXB8fg8s2+b51TtYt6uK+mAIr9NBdqqXkX3SyEhws6/Wzyc7K9i+vx6XaXD8gExOH5bNyu37AYOJ+RmYhsGO/bU8u2IHNf4weRleLhjblxU79vNJcQUNIYs+aT6G5SZT5Q9hGjCxfw9Mh8HuygZWb9+PZduYhsGoPmlU1AWoqA9i25Duc5Puc/HxjgrCls2eaj89Uzz0y/BhYLCjop5+GT4uKeyP22lSHwhzx8vr+HhHBUluB/0zk3A6TPpm+BjSM4kPt+3j0+2VJLgdjO2bDsDK4v3sqqjDH7JI8brI8LnpmeJhb02AHklu9tYEsLFJ9rj4/nF9mDigBx9tKef9L/awq6KB3DQvGT4P6T4Xq4r3s6G0ipqGMBmJTkzDINHrYny/DIZmJfNRcTlBy2JTSTVf7K0lZEFB3zR+cFwfnA6TvbV+MpM8NNSH+MNbn1NRFyAzyYXX5aTGH6ZnkpuGUJjqhjBZyW4S3U52VTbgD4XJTvEyIT+D/B5JzF/yGdv21QIwPDuRZJ+XQNgmP9PHL88cTtiyueGZ1RTvrycvPYGLxvelwh+ivMZPWoKLivogqQmNxz0UtthbEyAr2YNhGPjcDv6zq4qGYIg+aT4GZSWx+D8llNUE6Jns4cwROdQ2hNlZUc+mPTXs2l9H0LLJTvHQr0ciDtMkyeNkSHYSG0qr2bm/Ho/TIDPJi2ka5KR4qfYHAQMD8HkclFX5yU31kpHYeJzXbK9gd1UDCW4HSR4HDtNB3wwfx2Qns7fWz+6qBpZ+tofNe2txmgYj+6SQ7vPgME369/Bx4cR+rNhSzj9W7WD7/lr8IZvsVA/j+zaexV21vQKf28H3C/owLj+Dx4u2snhtCdvL60nyOhifn4HDMPjPripSvS6mn5DPZ2VV/HPNLvwhi4GZPk4fkUtNQ4iMJA+ZPjfrS6v4aFs5df4wI/ukMGlATzBg2ZZ9WF/+rGckuqmoC5Ca4GLltv2s2LqPan+YgT0T+Z+TBjJhQA+e+HAby7fso6SygaxkNzmpCaQluDFNKByQyfEDe+Awjcj7x9Yvfw4af7eCbCqr5pkVOzrsfayr6J3s4NZTsggkVGE4G5o8ZwBDspPxuByxKU5iyrBt2451EdCY1o7Uofj000/n3XffpbS0lNTUVACef/55fvCDH1BbW0tCQsJB6/j9fvx+f+TrA3NTVFZWRn36hbmvrOPhd7dgdYoj2vmZBuRlJLBt36HPvIl0B2k+F+P7p7NkfZneP1rhQLjJ6tUHw9n8pSkDGNknrUPrksPr378/119/Pddff/1BzzU0NLBlyxby8/Pxer1NnquqqiI1NbVFn99d6rJUbm4uvXv3jgQbgGHDhmHbNjt2NP9Xjcfjicwj1Z7zSc19ZR1/Xqpg0xqWjYKNCFBRF+SNdQo27cEGPt1REesympg+fTqGYTBv3rwmyxctWtTqyzL9+/dn/vz5LWpnGEaTx5Fm1u7KulS4mTRpErt27aKmpiay7LPPPsM0zZh+kwIhi4ff3RKz1xcRkUOzAX8wfMjnw5ZN0Rf7+OeanRR9sY9wB6RMr9fLb3/7W/bv39/ur3XAr3/9a0pKSiKP1atXN9suGAx2WE3tJabhpqamhjVr1rBmzRoAtmzZwpo1ayguLgZg1qxZXHrppZH2F154IT169GDGjBmsW7eOpUuX8vOf/5zLLrus2UtSHeWvRVv1F5eISCf2eVlNs8sXry3hxN++yQUPf8h1T6/hgoc/5MTfvsnitSXtWs/kyZPJyclh7ty5h233j3/8g2OPPRaPx0P//v25++67I8+dfPLJbNu2jRtuuCFyNuZwkpOTycnJiTx69uwJNHYLefDBBznnnHNITEzkjjvuIBwOc/nll5Ofn09CQgJDhw7l3nvvbbK9k08++aBLS+eeey7Tp0+PfF1WVsbZZ59NQkIC+fn5/O1vf2vB0Tl6MQ03K1asoKCggIKCAgBmzpxJQUEBc+bMAaCkpCQSdACSkpJ44403qKioYNy4cVx00UWcffbZ/PGPf4xJ/QdsK6+L6euLiMjhWc10L128toQrn1hFSWXTzsillQ1c+cSqdg04DoeDO++8kz/96U+H7FaxcuVKzjvvPH74wx/y6aefcuuttzJ79mwWLlwINPY57dOnT5MzMm1166238t3vfpdPP/2Uyy67DMuy6NOnD8899xzr1q1jzpw5/PKXv+TZZ59t1XanT5/O9u3beeutt/j73//OAw88QFlZWZvrbKmY3i118sknc7j+zAe+gV93zDHH8MYbb7RjVa3XL0ODR4mIdGbmN85qhC2b215cR3OfQDaNHZFve3Edpw3PwWG2z63m3/3udxkzZgy33HILCxYsOOj5e+65h+985zvMnj0bgCFDhrBu3Truuusupk+fTkZGBg6HI3JG5khuvPFGbr755sjXd955J9deey3QeGVkxowZTdp//U7j/Px8ioqKePbZZznvvPNatH+fffYZr776KsuXL2f8+PEALFiwgGHDhrVo/aPRpfrcdFaXFPannX72RUQkCgZnJTX5evmW8oPO2HydDZRUNrB8S3m71vXb3/6Wxx57jPXr1x/03Pr165k0aVKTZZMmTeLzzz+PDGDYGj//+c8jXUHWrFnTpNvHuHHjDmp///33M3bsWHr27ElSUhJ/+ctfmlxNOZL169fjdDoZO3ZsZNkxxxxDWlpaq2tvLYWbKHA7TX58Un6syxARkWYYcNB4N2XVhw42bWnXVt/61reYMmUKs2bNatfXAcjMzGTQoEGRx9dDRmJiYpO2Tz/9ND/72c+4/PLLef3111mzZg0zZsxoMvu6aZoHXX3pLJ2RFW6iZNaZw/nJt/J1BqcVTAP69YhdR3CRziLN5+K04Vl6/2gHhxrnJivZe9Cy5rS03dGYN28eL774IkVFRU2WDxs2jPfff7/Jsvfff58hQ4bgcDSGNbfb3aazOEfy/vvvc8IJJ/DTn/6UgoICBg0axBdffNGkTc+ePZv08wmHw6xduzby9THHHEMoFGLlypWRZRs3bqSioiLq9X5TlxqhuLObdeZw/vf0YzRCsUYo1gjFGqFYIxTH2JFGKJ6Qn0FuqpfSyoZm+90YQE5q4+9nexs5ciQXXXTRQTfH/O///i/jx4/nN7/5Deeffz5FRUXcd999PPDAA5E2/fv3Z+nSpfzwhz/E4/GQmZkZlZoGDx7M448/zmuvvUZ+fj5//etf+eijj8jP/+oqxamnnsrMmTN5+eWXGThwIPfcc0+T4DJ06FDOOOMMfvKTn/Dggw/idDq5/vrrO+Tu5k4zQnFHac0IhyIi0nkdbjTbljhwtxTQJOAcOIH24MXHccaI3KMv9BumT59ORUUFixYtiizbunUrQ4cOJRAINLnU849//IM5c+bw+eefk5ubyzXXXMPPfvazyPMffvghP/nJT9i4cSN+v/+QN+kcblTg5mYI8Pv9XHHFFbzwwgsYhsEFF1xAamoqr776amT4lmAwyHXXXcczzzyD0+nkhhtu4MMPPyQtLS1yQ1BpaSk/+tGP+Pe//012dja33347s2fPbvcRihVuRESkSzracAONAee2F9c16Vycm+rllrOHt0uwkcOLVrjRZSkREem2zhiRy2nDc1i+pZyy6gaykhsvRbXX7d/SMRRuRESkW3OYBoUDe8S6DIki3S0lIiIicUXhRkREROKKwo2IiHRp3ey+mLgWre+lwo2IiHRJBway+/qoudK1HfheHvjetpU6FIuISJfkdDrx+Xzs2bMHl8uFaerv9a7Msiz27NmDz+fD6Ty6eKJwIyIiXZJhGOTm5rJlyxa2bdsW63IkCkzTpG/fvhjG0d2Kr3AjIiJdltvtZvDgwbo0FSfcbndUzsAp3IiISJdmmmabRyiW+KQLlCIiIhJXFG5EREQkrijciIiISFxRuBEREZG4onAjIiIicUXhRkREROKKwo2IiIjEFYUbERERiSsKNyIiIhJXFG5EREQkrijciIiISFxRuBEREZG4onAjIiIicUXhRkREROKKwo2IiIjElZiGm6VLl3L22WfTq1cvDMNg0aJFLV73/fffx+l0MmbMmHarT0RERLqemIab2tpaRo8ezf3339+q9SoqKrj00kv5zne+006ViYiISFfljOWLT506lalTp7Z6vSuuuIILL7wQh8PRqrM9IiIiEv+6XJ+bRx99lM2bN3PLLbfEuhQRERHphGJ65qa1Pv/8c2666SbeffddnM6Wle73+/H7/ZGvq6qq2qs8ERER6QS6zJmbcDjMhRdeyG233caQIUNavN7cuXNJTU2NPPLy8tqxShEREYk1w7ZtO9ZFABiGwQsvvMC5557b7PMVFRWkp6fjcDgiyyzLwrZtHA4Hr7/+OqeeeupB6zV35iYvL4/KykpSUlKivh8iIiISfVVVVaSmprbo87vLXJZKSUnh008/bbLsgQce4M033+Tvf/87+fn5za7n8XjweDwdUaKIiIh0AjENNzU1NWzatCny9ZYtW1izZg0ZGRn07duXWbNmsXPnTh5//HFM02TEiBFN1s/KysLr9R60XERERLqvmIabFStWcMopp0S+njlzJgDTpk1j4cKFlJSUUFxcHKvyREREpAvqNH1uOkprrtmJiIhI59Caz+8uc7eUiIiISEso3IiIiEhcUbgRERGRuKJwIyIiInFF4UZERETiisKNiIiIxBWFGxEREYkrXWb6ha6i/00vx7oEiaIUF2Qke+mXkcCeuiBVdWEs28Kww1T5LcKWTShs43KY5GUk0DPZzSfbq6jxhzkwgJQFOACvEyzDwLIgGLaxaPzroleaB7fDpKSygfpQ41puEzISXQRDFmEMfC4HfTMSAIPtFfXU1AcIWDYmBl6XgwSXgQnUh2zqAiHqgzYOA9J8LpK8TvbW+DEMgwSXg5xkN/6Qxd7aIIGwhcdh4DAMqv1h/CEL2waHCYkeBzYGNQ0hQnZjTXkZiQzvlcygnon8feUOdlb6MWxI9zkY1y+DHZV+bNvG4zRJTXCxp8aPaVuU1gSxLMhMchEM29T4QzgMA9u2qGwIY2OTleRmUHYKpwzN4vlVO9iyp5q6kI3HYZLqc5HgMti5348/ZOEwwbIhbIFhgNsBHodJmMZj2xCyMQEbcBhgAA4HBEJffT/SE12ELAvDMBjY00coDCWVDeyuDnTsD1mMmMC7vziV3hkJsS5FJOo0iF8UKdiISFfjdhh8dseZsS5D5Ig0iF8MKNiISFcUCNsM+dUrsS5DJKoUbqJAwUZEurJA2GZneX2syxCJGoUbERFh6h/fiXUJIlGjcCMiItT6w7EuQSRqFG5ERIREjyPWJYhEjcKNiIjw6rXfjnUJIlGjcBMFW+edFesSRETazO0wNN6NxBWFmyhRwBGRrkjj3Eg80gjFUbR13lm6LTzOaIRijVAcrzRCscQzjVAcZUvXlnHpEx9FfbvdgQE4DQh2op9Iz5cf8lkpHnxuF/6whQvYXxegKmDhNg0SPCblNQFq/BbQ+MFpG+B0mGSleDg2N5mq+hD1QYtaf4BdFQ3UBi0cBgzMTOSskb34fG8NO/fX0xAM0RC08IcsElwOhuUkMbxXGhX1QT7dWYnX5cC2bfZV1fHFvjqC4cYP8ASnQarPRXqim8r6MAkug6r6MF6XARgYQCAcpqIuRMiy8bgcnDMmB3/Q5rPSamr8ITIS3YBN8b56yusCGLZNcoKLnLQESvfXUR0IY1k2boeJw2GQ6HHRJ9WLw2HQELSpCwTZVV5LVbDx2HkdkJ2awL6aBmoDNjZgGtDD5yK/ZyIpXhc9kjxsK69l655a/MEQDeHGb36K18kZI3LYsb+Bkop6yqobqKwPEbIaf06ykt2kJjipCVg4TYN0nwvbttlZ0YCBTYLbSciyCdswoEcC3x6STXqSm9f/U8oXe2oJhMIYtkV5fZhQ2CJkNR5Hp9H4oR+yG1/H6zIJhr/8vpoABg0hGwNIS3Awsk8qDtOkrNqPy2HQELSoqg9hGja1gTDVDSEsu3GbLqeBYRjYNngcYJoO0hPdJHkcNARC7K0LYWITCoepDzaGZqfDwOdx4nOZ7K72gw0eV+MJd8sCr8vAYZqELRvbhvpAYxD1uhwke5w4DJvaoEV9MNz4uk4Th9n48+BxmqT4XOyu8oNtU//lz2TIagzGTodJyLIJhm0cJqQnuDAMqPaHCYZsPC6TRLcDn9tJis/NcXlplFTW8dGWcvbXN+6304Avfy1i4tkfFTJhUEbsCpCoas3nt8JNFOmsjYhI56NuA/FB0y/EgIKNiEjnpPfn7kfhJgqWri2LdQkiInIYyzeVx7oE6UAKN1GgPjYiIp3bef9XFOsSpAMp3IiIiEhcUbgRERGRuKJwEwWPXzw+1iWIiMhhPPujwliXIB1I4SYKvjUiK9YliIjIYWi8m+5F4SZKNI6CiEjnpPfn7kfTL0TR1nlnaYTio6ARijVCsUYo1gjF0aQRirsvjVAsIiIinZ5GKBYREZFuS+FGRERE4kpMw83SpUs5++yz6dWrF4ZhsGjRosO2f/755znttNPo2bMnKSkpFBYW8tprr3VMsSIiItIlxDTc1NbWMnr0aO6///4WtV+6dCmnnXYar7zyCitXruSUU07h7LPPZvXq1e1cqYiIiHQVnaZDsWEYvPDCC5x77rmtWu/YY4/l/PPPZ86cOS1qrw7FIiIiXU9rPr+79K3glmVRXV1NRsahb/Xz+/34/f7I11VVVR1RmoiIiMRIl+5Q/Pvf/56amhrOO++8Q7aZO3cuqampkUdeXl4HVigiIiIdrcuGmyeffJLbbruNZ599lqysQ09/MGvWLCorKyOP7du3d2CVIiIi0tG65GWpp59+mh/96Ec899xzTJ48+bBtPR4PHo+ngyoTERGRWOtyZ26eeuopZsyYwVNPPcVZZ2m+EBEREWkqpmduampq2LRpU+TrLVu2sGbNGjIyMujbty+zZs1i586dPP7440Djpahp06Zx7733MnHiREpLSwFISEggNTU1JvsgIiIinUtMz9ysWLGCgoICCgoKAJg5cyYFBQWR27pLSkooLi6OtP/LX/5CKBTiqquuIjc3N/K47rrrYlK/iIiIdD6dZpybjqJxbkRERLoeTZwpIiIi3ZbCjYiIiMQVhRsRERGJKwo3IiIiElcUbkRERCSuKNyIiIhIXFG4ERERkbiicCMiIiJxReFGRERE4orCjYiIiMQVhRsRERGJKwo3IiIiElcUbkRERCSuKNyIiIhIXFG4ERERkbiicCMiIiJxReFGRERE4orCjYiIiMQVhRsRERGJKwo3IiIiElcUbkRERCSuKNyIiIhIXFG4ERERkbiicCMiIiJxReFGRERE4orCjYiIiMQVhRsRERGJKwo3IiIiElcUbkRERCSuKNyIiIhIXFG4ERERkbgS03CzdOlSzj77bHr16oVhGCxatOiI67z99tscd9xxeDweBg0axMKFC9u9ThEREek6YhpuamtrGT16NPfff3+L2m/ZsoWzzjqLU045hTVr1nD99dfzox/9iNdee62dKxUREZGuwhnLF586dSpTp05tcfuHHnqI/Px87r77bgCGDRvGe++9xx/+8AemTJnSXmWKiIhIF9Kl+twUFRUxefLkJsumTJlCUVFRjCoSERGRziamZ25aq7S0lOzs7CbLsrOzqaqqor6+noSEhIPW8fv9+P3+yNdVVVXtXqeIiIjETpc6c9MWc+fOJTU1NfLIy8uLdUkiIiLSjrpUuMnJyWH37t1Nlu3evZuUlJRmz9oAzJo1i8rKyshj+/btHVGqiIiIxEiXuixVWFjIK6+80mTZG2+8QWFh4SHX8Xg8eDye9i5NREREOomYnrmpqalhzZo1rFmzBmi81XvNmjUUFxcDjWddLr300kj7K664gs2bN/OLX/yCDRs28MADD/Dss89yww03xKJ8ERER6YRiGm5WrFhBQUEBBQUFAMycOZOCggLmzJkDQElJSSToAOTn5/Pyyy/zxhtvMHr0aO6++27+7//+T7eBi4iISIRh27Yd6yI6UlVVFampqVRWVpKSkhLrckRERKQFWvP53aU6FIuIiIgcicKNiIiIxBWFGxEREYkrCjciIiISVxRuREREJK4o3IiIiEhcUbgRERGRuNKmcLN7924uueQSevXqhdPpxOFwNHmIiIiIxEqb5paaPn06xcXFzJ49m9zcXAzDiHZdIiIiIm3SpnDz3nvv8e677zJmzJgolyMiIiJydNp0WSovL49uNmuDiIiIdBFtCjfz58/npptuYuvWrVEuR0REROTotOmy1Pnnn09dXR0DBw7E5/PhcrmaPF9eXh6V4kRERERaq03hZv78+VEuQ0RERCQ62hRupk2bFu06RERERKKiTeEGIBwOs2jRItavXw/AscceyznnnKNxbkRERCSm2hRuNm3axJlnnsnOnTsZOnQoAHPnziUvL4+XX36ZgQMHRrVIERERkZZq091S1157LQMHDmT79u2sWrWKVatWUVxcTH5+Ptdee220axQRERFpsTaduXnnnXf48MMPycjIiCzr0aMH8+bNY9KkSVErTkRERKS12nTmxuPxUF1dfdDympoa3G73URclIiIi0lZtCjf/7//9P/7nf/6HZcuWYds2tm3z4YcfcsUVV3DOOedEu0YRERGRFmtTuPnjH//IwIEDKSwsxOv14vV6mTRpEoMGDeLee++Ndo0iIiIiLdamPjdpaWn885//5PPPP2fDhg0ADBs2jEGDBkW1OBEREZHWavM4NwCDBw9m8ODB0aolLoQtm/c27uHP727iiz21hC2bdJ+LtEQXW/fUUu0PEwzb2DbYQLLHJDXBhdvpoCEYxudxckx2EiP7pNMjycO+Gj+f7Khg1bZyqhpCOB0myR4HLgc0BKHGHyJoWZhAIGQT/HI+UxPok+LE4XSyu9qPP2Rj2eAwwOsySPS6qKkPEbYsDANcDpOgZeNxmCR7nVTV+akLQcj6anupPhepXgdlNQFsyybB4yTD56ZnsoceSR4s22br3lps28brdjCgZxIfb6+gtiFIZUOIUMjCAhwmgEGyx0FuWgIGsK82hNdp4Haa9E73MaZPKsu3lbNq237qAhYGNNZvgmXRuB0D0n0uclM87K8PsqfaT9AC22583uMAn9uBPximLtTBPwgi0im8cvVJDO+TEusypIMZdgun9545cya/+c1vSExMZObMmYdte88990SluPZQVVVFamoqlZWVpKRE9wd+8doSrn16DYEDiUBERDqFrfPOinUJcpRa8/nd4jM3q1evJhgMRv4vTS1eW8IVT6yKdRkiItKM/je9rIDTjbQ43Lz11lvN/l8aL0XNWfRprMsQEZHDWLejSpeouok23S112WWXNTvOTW1tLZdddtlRF9XVLN9STllNMNZliIjIYfy/+96NdQnSQdoUbh577DHq6+sPWl5fX8/jjz9+1EV1NWXVDbEuQUREjkC9IbuPVt0tVVVVFRm0r7q6Gq/XG3kuHA7zyiuvkJWVFfUiO7usZO+RG4mISEy16a956ZJaFW7S0tIwDAPDMBgyZMhBzxuGwW233Ra14rqKCfkZZCW5dGlKRKQTe+nqk2JdgnSQVoWbt956C9u2OfXUU/nHP/7RZOJMt9tNv3796NWrV9SL7OwcpsGvzx2pu6VERDoxdSbuPlp1lu7b3/42J598Mlu2bOG//uu/+Pa3vx15FBYWtjnY3H///fTv3x+v18vEiRNZvnz5YdvPnz+foUOHkpCQQF5eHjfccAMNDbHt93LGiFweuvg43E6d+BQR6Wx0G3j30qYRivv16wdAXV0dxcXFBAKBJs+PGjWqxdt65plnmDlzJg899BATJ05k/vz5TJkyhY0bNzbbf+fJJ5/kpptu4pFHHuGEE07gs88+Y/r06RiGEfPBA88Ykcv6X+dohGKNUCwinYRGKO6eWjxC8dft2bOHGTNm8Oqrrzb7fDgcbvG2Jk6cyPjx47nvvvsAsCyLvLw8rrnmGm666aaD2l999dWsX7+eJUuWRJb97//+L8uWLeO999474uu15wjFIiIi0j5a8/ndpmso119/PRUVFSxbtoyEhAQWL17MY489xuDBg/nXv/7V4u0EAgFWrlzJ5MmTvyrINJk8eTJFRUXNrnPCCSewcuXKyKWrzZs388orr3DmmWe2ZVdEREQkzrTpstSbb77JP//5T8aNG4dpmvTr14/TTjuNlJQU5s6dy1lnteza5t69ewmHw2RnZzdZnp2dHZlt/JsuvPBC9u7dy4knnoht24RCIa644gp++ctfNtve7/fj9/sjX1dVVbVwL0VERKQratOZm9ra2kh/mPT0dPbs2QPAyJEjWbWqfe8Yevvtt7nzzjt54IEHWLVqFc8//zwvv/wyv/nNb5ptP3fuXFJTUyOPvLy8dq1PREREYqtN4Wbo0KFs3LgRgNGjR/PnP/+ZnTt38tBDD5Gbm9vi7WRmZuJwONi9e3eT5bt37yYnJ6fZdWbPns0ll1zCj370I0aOHMl3v/td7rzzTubOnYtlHTz+5KxZs6isrIw8tm/f3oo9FRERka6mTeHmuuuuo6SkBIBbbrmFV199lb59+/LHP/6RO++8s8XbcbvdjB07tknnYMuyWLJkCYWFhc2uU1dXh2k2LdvhcADQXN9oj8dDSkpKk4eIiIjErzb1ubn44osj/x87dizbtm1jw4YN9O3bl8zMzFZta+bMmUybNo1x48YxYcIE5s+fT21tLTNmzADg0ksvpXfv3sydOxeAs88+m3vuuYeCggImTpzIpk2bmD17NmeffXYk5IiIiEj31aZw800+n4/jjjuuTeuef/757Nmzhzlz5lBaWsqYMWNYvHhxpJNxcXFxkzM1N998M4ZhcPPNN7Nz50569uzJ2WefzR133BGNXREREZEursXj3MycObPFG431YHqHo3FuREREup7WfH63+MzN6tWrW9TOMIyWblJEREQk6locbt566632rENEREQkKqLS50YklgIhi8c+2Moj/15PSeDI7eNFutckxeuitMpP4MtREL5+jdkEkjwmXpeDOn+IhqDN16fYctE4Bxdf/vv1dVM9BhYG4bCFPwwG4HQY5CS5cLlcOB1QWRciZFkEwjY19SFCNLZzmOBzmaT6XKR7neyvD7K3NkggZBP+2ot4HeBxGdQHbWwLDAOCFjhNSHaDw+HEssHGoM4fJBBu3Kdv7oNpNq538EAQjQzAaTT+xzQMklwGdSGLhi83ZBiN85Y1t16iq3F+NcM0yEn2UOMPU1EfxAYSHJCZ4qWyPkRlfYiw3bjOgXPX36zH/PIYO75sFPpag2SPgdMwqPZb2DYYZuMcaU2OlwFujwO3wyTF68DGprQqSChkEbbB5YCMRDd56V52VwWobAhiWWBj4zQMAmGbQNgifJhjBfDk9ImccEzrbgwR6WzaNLfUKaecctjLT2+++eZRFdWe1OemazoQYJZv3UedP0QPnxvTNNlaXsua7ZWxLk8k7nx2+1TczjaNFiLSLtqlz83XjRkzpsnXwWCQNWvWsHbtWqZNm9aWTYoAELbsL2dV/4Iv9tQQCtvUBkI0hFqdwUXkKAy5+VV+NCmfm88eHutSRFqtTeHmD3/4Q7PLb731Vmpqao6qIOkewpbN8i3l7KqoZ3VxOaWVDWzfX8/G3fr5Eeks/u/9LTy3ajv3XXAcJwzKxGHqhhHpGtp0WepQNm3axIQJEygvL4/WJqNOl6U6TiBk8deirWzeU8Pu6gZsG+oCYXaU17GrsqFJfwIR6dzcDph//nGcOarlU+yIRFO7X5Y6lKKiIrxebzQ3KZ1U2LL54PO9/GP1DuoCYY7rm4aNzaptldT6A2zZW0tJVTfq3SsS5wJh+OmTq7hsW3/mnH1srMsROaw2hZvvfe97Tb62bZuSkhJWrFjB7Nmzo1KYxF7Ysvnwi30Ubd6LZUNqgovKuiDLt+xlRXHTTryvr9t9iK2ISDx55P2tLNu8l5ev+3asSxE5pDaFm9TU1CZfm6bJ0KFD+fWvf83pp58elcKk/R0ILx9s3suOffXsrW0gweWgZ7KXz8uqWVVc0ewtsiLSvf2npIZRt77G6jmnqx+OdEpR7XPTFXTHPjcHQsz7m/ayZns5e6oDlNcG2F8fVHgRkaMyrm8q100eqg7H0u46rM/NihUrWL9+PQDDhw9n7NixR7M5OQphy+bDzfso+mIfYduiojbAhtJqtu6rZX9d6MgbEBFpgxXFlVzyyHIcBvzhv8dwznG9Y12SSNvO3OzYsYMLLriA999/n7S0NAAqKio44YQTePrpp+nTp0+064yarnzmpqYhxPVPr2Lj7mpMwyAn1UsobGEYBp/uqMAfjnWF0pkcGKHYBqr9hxuTtutw0voRimPBpHX1tGSEYgPwuQwcDhOPw8A0oarBivoIxUerb7qHt37+HZ3Fkahrzed3m8LNGWecQUVFBY899hhDhw4FYOPGjcyYMYOUlBQWL17ctso7QFcINwfGgCmrbiAzyUMoZHH1kyupDnSmt+/OweM0mFbYj9c+2cm2yuBRbeuLO8/sUm/IX/85yUr2MiE/45D1N9f2jXWl3PbiOkoqGw5qn+h2UBcM8/V3B9OA7wzL4t/ryoCm0zUYX/va+MZz0TL7rGFcftKAFrWd88+1PF60rR2qOLKsJBe3njOSq55cddjjYAAPXnwcZ4w4+NbqxWtLmPnsx9QFDv8XS26ql1vOHs4ZI3KbnL0Fm8IBmRw/sMchfybqA2G+e/+7bNhd2/Kda4W7fzCK74/La5dtS/fU7uEmISGBDz74gIKCgibLV65cyUknnURdXV1rN9lhOkO4CYQsFr63hdfWlVJZ5ycQtqn2h8G2cJiNf735QwoyByR7HPRIclM4oAenH5PDyh37AYPCgT04fsBXb94nzlvCjoqDP6hb6i8Xj+X0ETlRqrprOBB6SqsaKK/xk5HoJic1gQn5GYQtm78WbWVbeR39MnxcUtgft9Nk8dqSg0LRgQ9Z4KDnEj0Oao/ytKJpwIbftHw6gAXvbuY3L68/qtc8GhmJbsprjzwUQm6ql/duPLVJAFm8toQrnljVotc5sNb/fCufZ1bsoKKuacBP87mY972RzQaoA2Ho8aItLFlfRnu85ZjAiptPIyPJHf2NS7fT7n1u8vLyCAYP/is5HA7Tq1evtmwyrhyYQuAv721me3kNpRV+Al9GSI8JcXKFIGo8ZuMHYMgGl2liWRZel0laogef20mvNC+JHid7agL83webCYUtisvr+NuHW0n0uBjTN5XhOSkc1zeNHRWlba7jiidW8tDFY3n7szI+3VlJitfFZYX92Vxex/b9dfRJSyAUtnhzYxnYMCQnmYK+6VTUBdhXE+DTnZU0BMP0SU/g3NG92bS3lm3ltRjA6D5pVNYHSfO5qagLkJHoJivZi2XbLNtSjm3bpPlcZCZ7yUx0s6G0im3ldRhAQV46PZM9bCitpri8jrBlUdUQpLSygV6pCSR6nOyt8ZPkcfK94/owcUAPPtpSTtHmvdg2JHqcvL9pD5X1QXJSvZw+PJeK2gD/KamkLhAmK9lDstdFaVUDvdK8ZCV7CVs2K7ftJzPZwzG5KYSCFr/4e+OZhPH9M3jjhm/z1PJiPtyyjy/Kakh0myz9rIzTjsnhuwW92Lm/nr01AbwuB4Zhs2NfLRvK2v5Hz9Rjs1i2eR9Fm/exq6KeXqkJpPpcVNQFKa2sJyc1gYxEF2kJLj7eUdHs2aiO1JJgA1BS2cDC97cwfVI+AB98vpeZz65p8esc+Mv0z0u3NPt8RV2QK55YRZ80D1kpCfTN8PHdMb1Zvb2Ch9/dTO0RzgwdLQs47vY3SPaYrLnljC51ZlS6tjadufnnP//JnXfeyf3338+4ceOAxs7F11xzDTfeeCPnnntutOuMmvY+c7N4bQnXPr2GgM68SBfWXpeWpHlpPheBkHXEy1Bd3UOHuAwn0hLtflkqPT2duro6QqEQTmfjyZ8D/09MTGzStrNNxdCe4aY1p5NFRLojBRxpq3a/LDV//vy2rBbXwpbNnEWfxroMEZFO7ebnP+a04Tm6RCXtqk3hZtq0adGuo8tbvqWcspqju1tHRCTe7a0Ls3xLOYUDe8S6FIljbR7ELxwOs2jRosggfsceeyznnHMODocjasV1JWXVse3AKCLSVej9Utpbm8LNpk2bOPPMM9m5c2dknJu5c+eSl5fHyy+/zMCBA6NaZFeQlazZ0EVEWkLvl9LeWjZoxDdce+21DBw4kO3bt7Nq1SpWrVpFcXEx+fn5XHvttdGusUuYkJ9BVpIr1mWIiHRqmT4HE/IzYl2GxLk2hZt33nmH3/3ud2RkfPUD2qNHD+bNm8c777wTteK6Eodp8OtzR8a6DBGJQ6cNz4p1CVFz+/dGqzOxtLs2hRuPx0N1dfVBy2tqanC7u+9IlGeMyOWhi49r8SiqIp1VvH70+NwOPJ3g9/Obn+3pPhc+98H9FdN9Lh66+DgevnQ8P/lW/kHrdSWmodvApeO0aZybSy+9lFWrVrFgwQImTJgAwLJly/jxj3/M2LFjWbhwYbTrjJqOmH7hcCMUZ/ocDOiZzP76ANgGTodJZV0DdUEbp2mQluBieK8Uhuemsq/Oz/uf72FXRQNByybB5aBvRiKnHZvN4KxkFn6whf21fjwuB4Ozkvm8rIaGQIi6QBgTi4BlkJ3i5ZShWeysrGN7eQMJLpPJw7PZXVXP35YVU1kXxOkwGNjDR1KCh+G9k6n3hzEMg/49Ejl/fF+eWl7M8q37qPOHyPC5cThMeqcnMKFfBht2V/HR1v00BMMck5PM1n21NAQt8jMT+eWZw3GYBn8t2srWfbX4Q2HW7apif20An9tJ3wwfiV4XCW6DfdWByFxG/mAYj9PAMEwCYYvcVO+Xo/AGqA+EIiMUNwStJiMUbyitYkNpY+gempVMUkLjyL2JHhdDspJYX1LFuxtLqfja4LHj8pLon5XCxtIaUhNcXHp8/24/QvGkgT0Zn5/Bym37v5rfLGjxwsc7IyMUX3x8P1YV7+fdz/fw3ud7AZtRfVI57ZgcVm7fT9i2qa4PYdk2e6r9ZCS6KK8NkpXiZUBmIhdO7Meqbfv5YPNedu2vJzvFS7U/iE1jsEr2NNZj29A73UthfiYYtHiE4t3VfhJdTo7JTaaqIYRpEJlrCeCDTXv5x6od1PpDZCZ5qAuEqA9aFPRNw2EYbNtXS1m1P1Lvgd+Dj7buI8HlxOOCTWW11DSEyEh0YxgG/qCFxwE4DIIhmz7pjaMBOx0mZTX+JtNbjO2XHjm+B+b6Avjwi30Ubd5Lc9OLQOPULY2/T3VYtkWKx4Xx5ftGRV2QXZX1ZCa72LqnjpIqP7X+EGkek6ANHpczMkKx02myt8ZPZpIH7MYOvuW1AdJ9bvbVBiiv9bNzfz2b9zbOO3Vs7xRMYEdFA73TvGDDf0qqSHI7qAuE2VlRTyBs0TOp8ec6ZMNnpdWRZbeceSwnH5utMzZyVNp9EL+KigqmT5/Oiy++2GQQv3POOYeFCxeSmpratso7QGeYW0pERERap90G8bMsi7vuuot//etfBAIBzj33XKZNm4ZhGAwbNoxBgwYdVeEiIiIiR6tV4eaOO+7g1ltvZfLkySQkJPDKK6+QmprKI4880l71iYiIiLRKq3rWPf744zzwwAO89tprLFq0iBdffJG//e1vWJYmiRQREZHOoVXhpri4mDPPPDPy9eTJkzEMg127dkW9MBEREZG2aNVlqVAohNfbdGRJl8tFMKg5leTwahpCXPHX5bz3xf5Yl3LUXAZ4nAZg4HYa+EM2YOEPQehr3fOdBqQkOHGbBrWBMIGwRSgMbie4HSbJXieBsE3YsqnxhwiEG9dzOyAQJnLnkNOAsP3l7cMGeB2Q4HYRtGxs2yYYsjAMA6cJBja1AZtgC24TMGnclmGaBMONZ19dJtiGgWXZNIS/uiXcBJwmJHqdeJwOqhsCWJaB02ngNS3qgjb1wcb6XA5wmiYmFnUBCLXgmDqMxv0M2TTuOOB0GNi2jQ3YNlhfHgOX08DtMAmHw/jDELK+OlaJ7saK/UE78r1wmkRu/w5ZFk7DoD5oc+B8s9uEgNXYzmk0bu/rx+/AX4DNnZ/2OhtrtIAEp0lumhevw2RvrZ+y6hAhy+ZI3wqP2bh/gVbf2iGHYtL4s2LZX/4Mf/k7dMCBm+5twGE2/s7VBWn2e2UACQ6oDzf//AFpHoPLvz2In3xrkIYD6QRadbeUaZpMnToVj8cTWfbiiy9y6qmnkpiYGFn2/PPPt6qI+++/n7vuuovS0lJGjx7Nn/70p8gt5s2pqKjgV7/6Fc8//zzl5eX069eP+fPnNzmrdCi6W6rjnXPfu3yyoyrWZYiIdIiffCufWWcOj3UZcafd7pZqbjbwiy++uHXVfcMzzzzDzJkzeeihh5g4cSLz589nypQpbNy4kaysg0flDAQCnHbaaWRlZfH3v/+d3r17s23bNtLS0o6qDmkfCjYi0t38eekWAAWcGGrTODfRNHHiRMaPH899990HNN5unpeXxzXXXMNNN910UPuHHnqIu+66iw0bNuBytX4uJ5256Tg1DSFG3PparMsQEYmJz26fqktUUdSaz++YHvVAIMDKlSuZPHlyZJlpmkyePJmioqJm1/nXv/5FYWEhV111FdnZ2YwYMYI777yTcDjcbHu/309VVVWTh3SMG55ZHesSRERi5q9FW2NdQrcV03Czd+9ewuEw2dnZTZZnZ2dTWlra7DqbN2/m73//O+FwmFdeeYXZs2dz9913c/vttzfbfu7cuaSmpkYeeXl5Ud8PaV7x/vpYlyAiEjPbyutiXUK31eXOl1mWRVZWFn/5y18YO3Ys559/Pr/61a946KGHmm0/a9YsKisrI4/t27d3cMXdV9/0hFiXICISM/0yfLEuoduKabjJzMzE4XCwe/fuJst3795NTk5Os+vk5uYyZMgQHI6vZtAdNmwYpaWlBAKBg9p7PB5SUlKaPKRj/OH8gliXICISM5cU9o91Cd1WTMON2+1m7NixLFmyJLLMsiyWLFlCYWFhs+tMmjSJTZs2NRkV+bPPPiM3Nxe3293uNUvLJXmdjOqjMCki3c9PvpWvzsQxFPMjP3PmTB5++GEee+wx1q9fz5VXXkltbS0zZswA4NJLL2XWrFmR9ldeeSXl5eVcd911fPbZZ7z88svceeedXHXVVbHaBTmMf119kgKOiHQrGucm9lo1zk17OP/889mzZw9z5syhtLSUMWPGsHjx4kgn4+LiYkzzqwyWl5fHa6+9xg033MCoUaPo3bs31113HTfeeGOsdkGO4F9Xn6QRijVC8WFphGKNUBxNGqFYYj7OTUfTODciIiJdT5cZ50ZEREQk2hRuREREJK4o3IiIiEhcUbgRERGRuKJwIyIiInFF4UZERETiisKNiIiIxBWFGxEREYkrCjciIiISVxRuREREJK4o3IiIiEhcifnEmfEmbNksXV/G715fz+a9ddi2jddlYtnQELRwmJDodmDbELRsXA6TnDQv3x6cxaRBmYRCFv/3/hY2lVUTDIUIWgYhyyYctkj0OPA6HbicJqGwRY0/RG3AIvzl5HAHJg80+XICRMDpMAEbj8uBy2ycSK4mYJHscTC8VwpJXhe79texo6IBp2HgD4UxDPC6nIzrl8Z7m/awv65xxjif2yQj0U1qgovt++uoqA9HJpJzmY0TB1qAP2ThNBonYHSYYNsGbtPGNgycDgceh0lDMETYtrEsm7DVeCzC1leTEzoM6OFzUOO3qA/ZGHw5SSE2oTB4XA4SXAYep8n+2gC1LZmdsQ08BjgcJglug2AY/MEwAatxUr4Ep8Fx/dJxOpzsrqpnX3UD++uD2DYke10Mzk6iZ5IXizCby2rZUdFAMGThdIDTNDAMk8xkD+P6ZVDQN4012yvYUFJJjT9Mz2QPI3qnUVkfYGNpNXuq/XicBm6ng0DIoqIuiD8U/nLSPxOf14XP6aA2EKKiPojbYZKZ6CYMJHtcWHaY/bVBgmGbtEQ3uakJZCW72bq3hl2VfhoCIWoDYSwbMnxOctN9lNcEKC6vI2w1ToaZ4XNhY2NgYjpMfG4Hx+Qm871RfdhYVs3r60ooqw7gcZrUNAQJWTZOh0GS24mNTXltkIZw40SfptF4DH1uJ6FwmLDd+D1P9DjBhip/GP+X7dK9DvwWNATDOAwDt8MgYNn4gzaGAaYJqV4nvdISCFoQCFrsrwsQCodxmAaGaWJZjT9DhgFhC8KWhfnlz/uBCULTvA7G90/j011VVNWHsWwb0zRI8Tjp2yMBp8OB1+UgHLbYWFrF/vowTodBD5+L/pk+qv1hHFhsLKsjGLIIWTYep0HDl7NwOk3wukxqA1Zksk+AnkkueiR6KK/xUx8K4zQbf8+SvE4CIYt9NX5qGkIEwy2bEFW+YtL8hKed1YkDUnjo0kKSvPpoPlqaODOKFq8t4eonVxOyutUhFRGRKBrVJ4V/XX1SrMvodDRxZgwsXlvCFU+sUrAREZGj8smOKs65791Yl9GlKdxEQdiymf3CJ7EuQ0RE4sQnO6qoaWin6+3dgMJNFCzfUs6e9ur0ISIi3dINz6yOdQldlsJNFJRVN8S6BBERiTPF++tjXUKXpXATBVnJ3liXICIicaZvekKsS+iyFG6iYEJ+Bj0TdeueiIhEzx/OL4h1CV2Wwk0UOEyD33x3VKzLEBGRODGqT4rGuzkKCjdRcsaIXB66+DicphHrUkREpAvTODdHT7Ewis4YkcvG23M0QrFGKNYIxRqhWCMUdwIaobj70gjFIiIi0ulphGIRERHpthRuREREJK4o3IiIiEhcUbgRERGRuKJwIyIiInFF4UZERETiisKNiIiIxBWFGxEREYkrnSLc3H///fTv3x+v18vEiRNZvnx5i9Z7+umnMQyDc889t30LFBERkS4j5uHmmWeeYebMmdxyyy2sWrWK0aNHM2XKFMrKyg673tatW/nZz37GSSdp/g0RERH5SszDzT333MOPf/xjZsyYwfDhw3nooYfw+Xw88sgjh1wnHA5z0UUXcdtttzFgwIAOrFZEREQ6u5iGm0AgwMqVK5k8eXJkmWmaTJ48maKiokOu9+tf/5qsrCwuv/zyjihTREREupCYTj26d+9ewuEw2dnZTZZnZ2ezYcOGZtd57733WLBgAWvWrGnRa/j9fvx+f+TrqqqqNtfbWuU1AY67/Y0Oe73DcRmQ6nNS29A4k3dGoou+GT4wDcprgiR5HKQmOCmvDbCzogGHaZDgNBmQlURuSgKpPjeGAUleJ+tLqthZXkdD2MJlGuysqKeyLohhQGqCk+G5qRimQfHeWnZV+TFsm8xkD8f2SqGyPsSeGj8GMDQ7mUSPk8/LagAYkp1MssfJf0qqSHA7SPc5+fCLfZRVB3CaMKBnEk6HSY0/hNOEYLhxzleXaRAM29QFLCrr/YTCNqbZODO3ZTfW5HU7yU72kJOagNdh8vLaEmr9IZymQUaSB4dhkJnkpkeSh701for31VFZHyBsQ2qCi1OHZHH6sTkUbdnH6//Zzf46P06HyeCsJMbkpZPkdfLKJzvZUeHHti16JnnwepzkpiSQmexi+756dlU2YFuNM8PvrQngD9lYto3LYZCb4mHCgJ4U9E3j4+0VrNtVyRd7awmGLNJ9Lnokudld5afaHybZ4yDRbbL/y1nZC/JSubRwAJUNQcpr/KT53JTXBthf58c0TAoH9mB8/wyWbd7Hcyu3s6Gk8XdgaHYyyQkuwrbNR5v3snVfAxbgcUCi10my28mAHj7qwza7q/3kpHr41uAsMpM8fLy9gl0V9WzeU0OdP4iFQV6Gj2G5KYztm06vdB8T8jNwmEZMft5FpHuL6azgu3btonfv3nzwwQcUFhZGlv/iF7/gnXfeYdmyZU3aV1dXM2rUKB544AGmTp0KwPTp06moqGDRokXNvsatt97KbbfddtDy9p4VfPztb7CnJtBu2xfp7DwOg9F5aVxz6mBOGJSpoCMiR6U1s4LHNNwEAgF8Ph9///vfm9zxNG3aNCoqKvjnP//ZpP2aNWsoKCjA4XBEllmWBTReztq4cSMDBw5ssk5zZ27y8vLaNdwo2Ig05TTgtGOzuXhif44f2ENBR0RarTXhJqaXpdxuN2PHjmXJkiWRcGNZFkuWLOHqq68+qP0xxxzDp59+2mTZzTffTHV1Nffeey95eXkHrePxePB4PO1Sf3PKawIKNiLfELLh1bW7eXXtbgBOHJjBw9MmkOB2HGFNEZHWi2m4AZg5cybTpk1j3LhxTJgwgfnz51NbW8uMGTMAuPTSS+nduzdz587F6/UyYsSIJuunpaUBHLQ8Vv77ofdiXYJIp/feF+UMm7OYdJ+L+eeN4cQhPXU2R0SiJubh5vzzz2fPnj3MmTOH0tJSxowZw+LFiyOdjIuLizHNmN+x3mLb9tXHugSRLmN/XZBpCz/C7TD44wUFnDEiN9YliUgciGmfm1hozTW7tuh/08tR36ZId9HD56JfDx9TRuQwY9IA3M6u84eNiLSvLtPnRkTk6/bVBdlXV8mq7ZXMfXUj007oy23njIx1WSLSxejPoihT90iR6Hnsg2LGd5KxokSk69CZmyhzmhC2Yl2FSPzYUxPglLve4qcnD+T1dbupD1rkZ/r45ZnDdbeViDRL4SbK9FYrXcXYvFSG5qawbV8t739R3myb3qkedlf5CR2mZ57XCUkeF3kZPsqq/OysbIh6rVv21fHzf3w1DMR7m+CvHxZzXN9Unrtiku60EpEmFG6izDYNsLpVH23pYpI8Tn73/VGcOeqrO5PCls2HX+yjaPNewKBwYA+OH9A42F7Yslm+pZzSynrKqhtYX1JNXSDM+P4ZTDuh/0Gdfl/8eBe/fOFTqhtC7b4vq4orGXrzq9x3oe60EpGv6G6pKBv6q5fxh6O+WZGoykh08d0xvZk8PKdd5oA6EIj+svQL3tq4J6rbPpQBmQnkpiQwOi+dSYMzI+FMROJDl5l+IRbi/VbwVK+Dygalq67OaUKog/pu5aZ6+dXUY9hV2cDr60oBg1OO6YlpwZLPyrBtGJqTzLh+GWSnegmFLF5Ys5O6QIjx/Xtw8fH9WLO9grLqBjITPWDA3ho/WcleJuRnELZsbnzuYxZ9vIuOfLNJcJlc8e1BXH3qIIUckTigcHMY8R5uRDoTr8tkSFYyI/ukMKZPGlUNIbbuq+XZFTvwd1B687kc/OTbA7j61MEKOSJdmMLNYSjciMRWqtckNyUBv2XjD4bZVek/8kpR4HWZXDC+L6cf2z6X4kSkfWkQPxHptCobLCobajv8dRuCFo9+sJVHP9iKacDxAzL4ybcGUlEfjFxCOxB4DvQZKqtuOOi5rztSu7Bl8+HmfRR9sQ+wKRyQ2WRW9EDI4q9FW9lWXkeftARsYGdFPf0yfFxSeHBnbRFpGZ25iTKduRGJXwYcsd+QA3CYEIjCVTeXCb1T3eyvD1EftAmFbUzgwH1oTgOSPQ7CGPROdZOVksDWfXXU+EO4THA6TBJcTnome8hIdFFeG8TrMtlXG2B3VeMZs2OyEklOdFPTEGJjSRWV9QFsTLKTXeyu8lPXjje9jeiVyLDcVLbvq2fj7hr8oRAGNg1BOHD4DL76v+vL3Bi0G0eg9TgNkhNc5KX7eGT6BFJ9rvYrVmJOl6UOo73DzYjZL1MTjPpmRUTkKKWZ0D83mZBtkJvqZUJ+j2aHM5DOSeHmMNo73Nz49495ZsWOqG9XRETaR5LbQWaSG5fDoGeyh4FZyRoBuxNSuDmM9g439YEww+Ysjvp2RUSkY6UlOOiVmsC+2gCpCW6+V9Cby07SbPWxonBzGO0dbgB+/PhHvLGurF22LSIisZWR6KJXqpdkj5Mkr0uXtzqIws1hdES4gc4XcJymgcdpUhvQAH8iIu3B9eXgmw4TeqV6mPP/RnLKsCwNOxAlCjeH0VHhBhovUd3x8n9YXVxBrT+Iy+nA53FQWx+iPmSR7nPzv5OHMGlIT1Zu28/28lqeXl5McXktGAYT+meQ5nNjmgb9MnwMyEjkkaKt7Kqsx+sySXE7CNkGeRk+vlvQG6dpsrfWT1qCi9f+U8KnO6tI9br48UkDOHFIT4CDbks9rl86T3y4jeVb9rGhtIod+xtaPIqsx2kSCFkdOuqsiEhX4wC+PbgHf7xoHElejcDSVgo3h9GR4aYr+vq4HZlJHrChrLqBvTUB9tcG2FVZT680L5MG9uT4gT0IWzaPfbCV5Vv2UesP0SPZQ98MHxP6ZbC+pIp/r99NlT/E0KwkkhNcmKZBfo9ELpzYOGT/rop6Vhfvp7SynnUl1exqhxmlRUQ6i1F9UvjX1SfFuowuSeHmMBRuOqe5r6zjz0u3xLoMEZF2p4DTNq35/FbvJ4m5QMjiLwo2ItJNfLKjipqGdhwdURRuJPb+WrRV/XZEpFu54ZnVsS4hrincSMxtK6+LdQkiIh2qeH99rEuIawo3EnP9MnyxLkFEpEP1TU+IdQlxTeFGYu6Swv5oFAgR6U7+cH5BrEuIa7rhvh3sqfLzX/e9y54aPw7DYETvFJymwfaKeuoCFglOkxRv4xg1BjbpiW5Kq/xU1gVJ8jo4b2wfdlY2sHTjXmr8QQwDTAMSXA7qgxaBsIXXaZCXkUTIsqkLhEhPcJGb5mVjSRU7KvwYBhzfP50LxvVj4bKtrC+potofxjQgJ8VDfs8k9tUEAPC64fPdtfiDNi4H5KX76JWWSHaqB5/bwYeby6lpCJLocZLsdeAPWQRCFh6nkwS3gyG5iXy8rZKSynr21wXBtrEx6JnkYmhuKqcNz+GTHRWs21nJ5n21BEMWYcsm0e0gr4ePQMjCaUIwCrMoi4h0dqP6pGi8m3amW8GjbNStr1GlXvAiItIM3Qbedq35/FZ0jCIFGxER+Sa3AScO0gjFHUlHOUr2VPkVbEREurkPb/oOOWneWJfR7alDcZR894H3Yl2CiIjE2JQ/vBnrEgSFm6jZUaE5kUREurtKf7fqxtppKdyIiIhIXFG4ERERiZJ0ryPWJQidJNzcf//99O/fH6/Xy8SJE1m+fPkh2z788MOcdNJJpKenk56ezuTJkw/bXkREpKO8ev3JsS5B6ATh5plnnmHmzJnccsstrFq1itGjRzNlyhTKysqabf/2229zwQUX8NZbb1FUVEReXh6nn346O3fu7ODKRUREvmKC7pTqJGI+iN/EiRMZP3489913HwCWZZGXl8c111zDTTfddMT1w+Ew6enp3HfffVx66aVHbN+eg/j1v+nlqG5PRES6jq3zzop1CXGtNZ/fMT1zEwgEWLlyJZMnT44sM02TyZMnU1RU1KJt1NXVEQwGycjIaPZ5v99PVVVVk0d70Q+2iEj3pPf/ziWm4Wbv3r2Ew2Gys7ObLM/Ozqa0tLRF27jxxhvp1atXk4D0dXPnziU1NTXyyMvLO+q6D6clP+AdOUmkC3DGcFZKE3AZHbvPIhJ/DMDnMnCb4DDAZTa+t0Dj3HuJTvhmX16fy2jy3nOk9yGDxm0muQxcLfx0XHjhOAWbTqhLj1A8b948nn76ad5++2283uavc86aNYuZM2dGvq6qqmrXgPP2J7uP2Ka564AuE8IWfH3uSOMQbVsjTGPAMQ0IHGJjBuAxwW+17PW8JrgcUBM8cnsLsFq5EyZNj8PX69QIEiLdkw3UBb96Bwh/7c3AsqG2mQHi64I2KR6DkAX1Qfug9w+XAbmpHm45awQnH5uNw9SfYfEipuEmMzMTh8PB7t1NA8Hu3bvJyck57Lq///3vmTdvHv/+978ZNWrUIdt5PB48Hk9U6j2So+lz09yM2NH4ILeAI40pZQMNrZiRu8FqXfvWOtSmFWxEpLWqDvMGGLShuMLP5X9biWnAAxcdxxkjcjuwOmkvMb0s5Xa7GTt2LEuWLIkssyyLJUuWUFhYeMj1fve73/Gb3/yGxYsXM27cuI4o9YjUmVhEpOuybLjiiVUsXlsS61IkCmJ+K/jMmTN5+OGHeeyxx1i/fj1XXnkltbW1zJgxA4BLL72UWbNmRdr/9re/Zfbs2TzyyCP079+f0tJSSktLqampidUutOhSlIiIdH43P/8x4dZeS5dOJ+Z9bs4//3z27NnDnDlzKC0tZcyYMSxevDjSybi4uBjT/CqDPfjggwQCAX7wgx802c4tt9zCrbfe2pGlR0x/ckVMXldERKJrb12Y5VvKKRzYI9alyFGIebgBuPrqq7n66qubfe7tt99u8vXWrVvbvyAREem2yqo1EXJXF/PLUiIiIp1JVrJGGe7qFG6iYOGFnaNTs4iIHJ1Mn4MJ+c0PCitdh8JNFJw8KvvIjUREpNO7/XujNd5NHFC4iRKNUCki0nWZBjx0sca5iRedokNxvNg67yze/mR3m+6eaq8Rig9Mf2ATmxGK2yLeRijurHVHs64DbyTNDBLbZg6+qq8dx4yUOKcRirsnhZsoO3lUNltH6SyOiIhIrCjcRJlGKo4vCQ6oD7dtXScHn8n45lmpznJWx+dsnKvHshvPmAS+PIt4YLLCBLeT8tpgpPasRAcNYahtCIMBPrdJVrKXHolOtpU3UN0QbDIPkEHjZIcGX74OjcfCAJwOA4/TINHtIMHlIGwb1IfCVNcHCHx5AA/U4jAb6/v69B8eB+RnJtI7LYF+mYm8uaGMylo/dUEL0zTwuZwke0321QYJhm0M2yYMGDYkuA2qGxq/hsa/5HuneXA4HNQHQoQsG9OAyoYwBjaJbicpXidgU9UQpqohiGWD24QUnxsDm8r6ELVf7vuhzkKKDO3h5tmrTibV54p1KXHJsG27M7y3dpiqqipSU1OprKwkJSUlqttWsBERkdbo1yOBd35+aqzL6BJa8/mtDsVRomAjIiKttW1fPd++681YlxF3FG6iQMFGRETaatu+eirrgrEuI64o3IiIiMTYZQuXx7qEuKJwIyIiEmO7KjWfVTQp3IiIiMRYr1TNZxVNCjciIiIx9sj0CbEuIa4o3IiIiMRQvx4JGu8myhRuREREYkTj3LQPhRsREZEY8ZnoNvB2oHAjIiISI+v31DP6169rIL8oU7gRERGJMY1UHF0KNyIiIp2ARiqOHoUbERGRTkIjFUeHwo2IiEgnoZGKo0PhJgp6xLoAERGJCxqpODoUbqJgX6wLEBGRuKCRiqND4UZERKQT0EjF0aNwIyIiEmNJbodGKo4ihRsREZEY++jm02JdQlxRuBEREYmh04ZnkeB2xLqMuOKMdQEiIiLd2Rvryuh/08utXs/48mG1or19mOcTnAZ90n0885MTyEhyt7qezkRnbkRERLogm5YHmwPtD6c+ZPP5nlqOu/0Nxt/+xlFUFnsKNyIiItLEnppAlw44neKy1P33389dd91FaWkpo0eP5k9/+hMTJhz6Xv/nnnuO2bNns3XrVgYPHsxvf/tbzjzzzA6sWEREJL7tqQm06XIZgNuEn35rID+dPAS3s+PPo8T8zM0zzzzDzJkzueWWW1i1ahWjR49mypQplJWVNdv+gw8+4IILLuDyyy9n9erVnHvuuZx77rmsXbu2gysXERGR5gQsmP/2Fwy5+VXmvrKuw1/fsG37SJfh2tXEiRMZP3489913HwCWZZGXl8c111zDTTfddFD7888/n9raWl566aXIsuOPP54xY8bw0EMPHfH1qqqqSE1NpbKykpSUlKOuv62pVkREpLv4ybfymXXm8KPaRms+v2N65iYQCLBy5UomT54cWWaaJpMnT6aoqKjZdYqKipq0B5gyZcoh27enKxa82uGvKSIi0tX8eekWAqHWdH8+OjENN3v37iUcDpOdnd1keXZ2NqWlpc2uU1pa2qr2fr+fqqqqJo9oWfx5x32jREREurK/Fm3tsNeKeZ+b9jZ37lxSU1Mjj7y8vFiXJCIi0u1sK6/rsNeKabjJzMzE4XCwe/fuJst3795NTk5Os+vk5OS0qv2sWbOorKyMPLZv3x6d4kVERKTF+mX4Ouy1Yhpu3G43Y8eOZcmSJZFllmWxZMkSCgsLm12nsLCwSXuAN95445DtPR4PKSkpTR7RcsbguD/xJSIiEhWXFPbvsNeK+afzzJkzefjhh3nsscdYv349V155JbW1tcyYMQOASy+9lFmzZkXaX3fddSxevJi7776bDRs2cOutt7JixQquvvrqDq/9ocundvhrioiIdDU/+VZ+h453E/NB/M4//3z27NnDnDlzKC0tZcyYMSxevDjSabi4uBjT/OqAnHDCCTz55JPcfPPN/PKXv2Tw4MEsWrSIESNGxKT+rfPO0u3gIiIihxCN28BbK+bj3HS0aI9zc8AVC17V3VMiIiK0zwjFrfn8jvmZm3ihS1QiIiKdQ8z73IiIiIhEk8KNiIiIxBWFGxEREYkrCjciIiISVxRuREREJK4o3IiIiEhcUbgRERGRuKJwIyIiInFF4UZERETiSrcbofjAbBNVVVUxrkRERERa6sDndktmjep24aa6uhqAvLy8GFciIiIirVVdXU1qauph23S7iTMty2LXrl0kJydjGEbUtltVVUVeXh7bt2+P6oScXZmOSVM6Hk3peBxMx6QpHY+DdedjYts21dXV9OrVC9M8fK+abnfmxjRN+vTp027bT0lJ6XY/cEeiY9KUjkdTOh4H0zFpSsfjYN31mBzpjM0B6lAsIiIicUXhRkREROKKwk2UeDwebrnlFjweT6xL6TR0TJrS8WhKx+NgOiZN6XgcTMekZbpdh2IRERGJbzpzIyIiInFF4UZERETiisKNiIiIxBWFmyi5//776d+/P16vl4kTJ7J8+fJYl9Qu5s6dy/jx40lOTiYrK4tzzz2XjRs3NmnT0NDAVVddRY8ePUhKSuL73/8+u3fvbtKmuLiYs846C5/PR1ZWFj//+c8JhUIduSvtYt68eRiGwfXXXx9Z1t2Ox86dO7n44ovp0aMHCQkJjBw5khUrVkSet22bOXPmkJubS0JCApMnT+bzzz9vso3y8nIuuugiUlJSSEtL4/LLL6empqajdyUqwuEws2fPJj8/n4SEBAYOHMhvfvObJkPIx/MxWbp0KWeffTa9evXCMAwWLVrU5Plo7fsnn3zCSSedhNfrJS8vj9/97nftvWttdrhjEgwGufHGGxk5ciSJiYn06tWLSy+9lF27djXZRrwdk6iz5ag9/fTTttvtth955BH7P//5j/3jH//YTktLs3fv3h3r0qJuypQp9qOPPmqvXbvWXrNmjX3mmWfaffv2tWtqaiJtrrjiCjsvL89esmSJvWLFCvv444+3TzjhhMjzoVDIHjFihD158mR79erV9iuvvGJnZmbas2bNisUuRc3y5cvt/v3726NGjbKvu+66yPLudDzKy8vtfv362dOnT7eXLVtmb9682X7ttdfsTZs2RdrMmzfPTk1NtRctWmR//PHH9jnnnGPn5+fb9fX1kTZnnHGGPXr0aPvDDz+03333XXvQoEH2BRdcEItdOmp33HGH3aNHD/ull16yt2zZYj/33HN2UlKSfe+990baxPMxeeWVV+xf/epX9vPPP28D9gsvvNDk+Wjse2VlpZ2dnW1fdNFF9tq1a+2nnnrKTkhIsP/85z931G62yuGOSUVFhT158mT7mWeesTds2GAXFRXZEyZMsMeOHdtkG/F2TKJN4SYKJkyYYF911VWRr8PhsN2rVy977ty5MayqY5SVldmA/c4779i23fiL6XK57Oeeey7SZv369TZgFxUV2bbd+IttmqZdWloaafPggw/aKSkptt/v79gdiJLq6mp78ODB9htvvGF/+9vfjoSb7nY8brzxRvvEE0885POWZdk5OTn2XXfdFVlWUVFhezwe+6mnnrJt27bXrVtnA/ZHH30UafPqq6/ahmHYO3fubL/i28lZZ51lX3bZZU2Wfe9737Mvuugi27a71zH55gd5tPb9gQcesNPT05v8vtx444320KFD23mPjl5zge+bli9fbgP2tm3bbNuO/2MSDbosdZQCgQArV65k8uTJkWWmaTJ58mSKiopiWFnHqKysBCAjIwOAlStXEgwGmxyPY445hr59+0aOR1FRESNHjiQ7OzvSZsqUKVRVVfGf//ynA6uPnquuuoqzzjqryX5D9zse//rXvxg3bhz//d//TVZWFgUFBTz88MOR57ds2UJpaWmT45GamsrEiRObHI+0tDTGjRsXaTN58mRM02TZsmUdtzNRcsIJJ7BkyRI+++wzAD7++GPee+89pk6dCnTPY3JAtPa9qKiIb33rW7jd7kibKVOmsHHjRvbv399Be9N+KisrMQyDtLQ0QMekJbrd3FLRtnfvXsLhcJMPJoDs7Gw2bNgQo6o6hmVZXH/99UyaNIkRI0YAUFpaitvtjvwSHpCdnU1paWmkTXPH68BzXc3TTz/NqlWr+Oijjw56rrsdj82bN/Pggw8yc+ZMfvnLX/LRRx9x7bXX4na7mTZtWmR/mtvfrx+PrKysJs87nU4yMjK63PEAuOmmm6iqquKYY47B4XAQDoe54447uOiiiwC65TE5IFr7XlpaSn5+/kHbOPBcenp6u9TfERoaGrjxxhu54IILInNJdfdj0hIKN9JmV111FWvXruW9996LdSkxs337dq677jreeOMNvF5vrMuJOcuyGDduHHfeeScABQUFrF27loceeohp06bFuLrYePbZZ/nb3/7Gk08+ybHHHsuaNWu4/vrr6dWrV7c9JtIywWCQ8847D9u2efDBB2NdTpeiy1JHKTMzE4fDcdDdL7t37yYnJydGVbW/q6++mpdeeom33nqrySzrOTk5BAIBKioqmrT/+vHIyclp9ngdeK4rWblyJWVlZRx33HE4nU6cTifvvPMOf/zjH3E6nWRnZ3er45Gbm8vw4cObLBs2bBjFxcXAV/tzuN+XnJwcysrKmjwfCoUoLy/vcscD4Oc//zk33XQTP/zhDxk5ciSXXHIJN9xwA3PnzgW65zE5IFr7Hk+/QwccCDbbtm3jjTfeaDIDeHc9Jq2hcHOU3G43Y8eOZcmSJZFllmWxZMkSCgsLY1hZ+7Btm6uvvpoXXniBN99886DTnmPHjsXlcjU5Hhs3bqS4uDhyPAoLC/n000+b/HIe+OX95gdjZ/ed73yHTz/9lDVr1kQe48aN46KLLor8vzsdj0mTJh00NMBnn31Gv379AMjPzycnJ6fJ8aiqqmLZsmVNjkdFRQUrV66MtHnzzTexLIuJEyd2wF5EV11dHabZ9K3W4XBgWRbQPY/JAdHa98LCQpYuXUowGIy0eeONNxg6dGiXvPxyINh8/vnn/Pvf/6ZHjx5Nnu+Ox6TVYt2jOR48/fTTtsfjsRcuXGivW7fO/p//+R87LS2tyd0v8eLKK6+0U1NT7bffftsuKSmJPOrq6iJtrrjiCrtv3772m2++aa9YscIuLCy0CwsLI88fuPX59NNPt9esWWMvXrzY7tmzZ5e89bk5X79byra71/FYvny57XQ67TvuuMP+/PPP7b/97W+2z+ezn3jiiUibefPm2WlpafY///lP+5NPPrH/67/+q9lbfwsKCuxly5bZ7733nj148OAucdtzc6ZNm2b37t07civ4888/b2dmZtq/+MUvIm3i+ZhUV1fbq1evtlevXm0D9j333GOvXr06cudPNPa9oqLCzs7Oti+55BJ77dq19tNPP237fL5Oe9vz4Y5JIBCwzznnHLtPnz72mjVrmrzPfv3Op3g7JtGmcBMlf/rTn+y+ffvabrfbnjBhgv3hhx/GuqR2ATT7ePTRRyNt6uvr7Z/+9Kd2enq67fP57O9+97t2SUlJk+1s3brVnjp1qp2QkGBnZmba//u//2sHg8EO3pv28c1w092Ox4svvmiPGDHC9ng89jHHHGP/5S9/afK8ZVn27Nmz7ezsbNvj8djf+c537I0bNzZps2/fPvuCCy6wk5KS7JSUFHvGjBl2dXV1R+5G1FRVVdnXXXed3bdvX9vr9doDBgywf/WrXzX5oIrnY/LWW281+54xbdo027ajt+8ff/yxfeKJJ9oej8fu3bu3PW/evI7axVY73DHZsmXLId9n33rrrcg24u2YRJtmBRcREZG4oj43IiIiElcUbkRERCSuKNyIiIhIXFG4ERERkbiicCMiIiJxReFGRERE4orCjYiIiMQVhRsRERGJKwo3IiIiElcUbkSkQxUVFeFwODjrrLNiXUqrnHzyyVx//fWxLkNEWkDhRkQ61IIFC7jmmmtYunQpu3btinU5IhKHFG5EpMPU1NTwzDPPcOWVV3LWWWexcOHCyHNvv/02hmHw2muvUVBQQEJCAqeeeiplZWW8+uqrDBs2jJSUFC688ELq6uoi6/n9fq699lqysrLwer2ceOKJfPTRR5HnFy5cSFpaWpM6Fi1ahGEYka9vvfVWxowZw1//+lf69+9PamoqP/zhD6murgZg+vTpvPPOO9x7770YhoFhGGzdurVdjpGIHD2FGxHpMM8++yzHHHMMQ4cO5eKLL+aRRx7hm3P33nrrrdx333188MEHbN++nfPOO4/58+fz5JNP8vLLL/P666/zpz/9KdL+F7/4Bf/4xz947LHHWLVqFYMGDWLKlCmUl5e3qrYvvviCRYsW8dJLL/HSSy/xzjvvMG/ePADuvfdeCgsL+fGPf0xJSQklJSXk5eUd/QERkXahcCMiHWbBggVcfPHFAJxxxhlUVlbyzjvvNGlz++23M2nSJAoKCrj88st55513ePDBBykoKOCkk07iBz/4AW+99RYAtbW1PPjgg9x1111MnTqV4cOH8/DDD5OQkMCCBQtaVZtlWSxcuJARI0Zw0kkncckll7BkyRIAUlNTcbvd+Hw+cnJyyMnJweFwROGIiEh7ULgRkQ6xceNGli9fzgUXXACA0+nk/PPPPyiEjBo1KvL/7OxsfD4fAwYMaLKsrKwMaDzbEgwGmTRpUuR5l8vFhAkTWL9+favq69+/P8nJyZGvc3NzI68jIl2LM9YFiEj3sGDBAkKhEL169Yoss20bj8fDfffdF1nmcrki/zcMo8nXB5ZZltXi1zVN86BLX8Fg8KB2R/s6ItJ56MyNiLS7UCjE448/zt13382aNWsij48//phevXrx1FNPtWm7AwcOxO128/7770eWBYNBPvroI4YPHw5Az549qa6upra2NtJmzZo1rX4tt9tNOBxuU50i0rF05kZE2t1LL73E/v37ufzyy0lNTW3y3Pe//30WLFjAXXfd1ertJiYmcuWVV/Lzn/+cjIwM+vbty+9+9zvq6uq4/PLLAZg4cSI+n49f/vKXXHvttSxbtqzJXVot1b9/f5YtW8bWrVtJSkoiIyMD09TfhyKdkX4zRaTdLViwgMmTJx8UbKAx3KxYsYJPPvmkTdueN28e3//+97nkkks47rjj2LRpE6+99hrp6ekAZGRk8MQTT/DKK68wcuRInnrqKW699dZWv87PfvYzHA4Hw4cPp2fPnhQXF7epXhFpf4b9zYvRIiIiIl2YztyIiIhIXFG4ERERkbiicCMiIiJxReFGRERE4orCjYiIiMQVhRsRERGJKwo3IiIiElcUbkRERCSuKNyIiIhIXFG4ERERkbiicCMiIiJxReFGRERE4sr/B7zszhWX8g6TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 0][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 0][\"city_pop\"])\n",
    "\n",
    "plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 1][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 1][\"city_pop\"])\n",
    "plt.legend([ \"Not Fraud\", \"Fraud\"])\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Population\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVlggv1lMvt2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjt1pnzgZcuO"
   },
   "source": [
    "# 7.) We want to compare oversampling, Undersampling and SMOTE across our 3 models (Logistic Regression, Logistic Regression Lasso and Decision Trees).\n",
    "\n",
    "# Make a dataframe that has a dual index and 9 Rows.\n",
    "# Calculate: Sensitivity, Specificity, Precision, Recall and F1 score. for out of sample data.\n",
    "# Notice any patterns across perfomance for this model. Does one totally out perform the others IE. over/under/smote or does a model perform better DT, Lasso, LR?\n",
    "# Choose what you think is the best model and why. test on Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0tIC3Nd1bx-N"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)  # Recall is the same as sensitivity\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return sensitivity, specificity, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weijiayu/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Sensitivity Specificity  \\\n",
      "Model                     Sampling Technique                           \n",
      "Logistic Regression       Oversampling          0.712934    0.919618   \n",
      "                          Undersampling         0.712934    0.918679   \n",
      "                          SMOTE                 0.712934    0.916884   \n",
      "Logistic Regression Lasso Oversampling          0.712934    0.919618   \n",
      "                          Undersampling         0.712934    0.919775   \n",
      "                          SMOTE                 0.712934    0.916848   \n",
      "Decision Trees            Oversampling          0.526814    0.998459   \n",
      "                          Undersampling         0.940063    0.946231   \n",
      "                          SMOTE                 0.716088    0.992811   \n",
      "\n",
      "                                             Precision    Recall  F1 Score  \n",
      "Model                     Sampling Technique                                \n",
      "Logistic Regression       Oversampling        0.032749  0.712934  0.062621  \n",
      "                          Undersampling       0.032383  0.712934  0.061952  \n",
      "                          SMOTE               0.031706  0.712934  0.060712  \n",
      "Logistic Regression Lasso Oversampling        0.032749  0.712934  0.062621  \n",
      "                          Undersampling       0.032811  0.712934  0.062734  \n",
      "                          SMOTE               0.031693  0.712934  0.060687  \n",
      "Decision Trees            Oversampling        0.566102  0.526814  0.545752  \n",
      "                          Undersampling       0.062566  0.940063  0.117323  \n",
      "                          SMOTE               0.275485  0.716088  0.397897  \n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Logistic Regression Lasso': LogisticRegression(penalty='l1', solver='saga', max_iter=1000),\n",
    "    'Decision Trees': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Define the sampling techniques\n",
    "sampling_techniques = {\n",
    "    'Oversampling': RandomOverSampler(random_state=42),\n",
    "    'Undersampling': RandomUnderSampler(random_state=42),\n",
    "    'SMOTE': SMOTE(random_state=42)\n",
    "}\n",
    "\n",
    "# DataFrame to store the performance metrics\n",
    "metrics = ['Sensitivity', 'Specificity', 'Precision', 'Recall', 'F1 Score']\n",
    "index = pd.MultiIndex.from_product([models.keys(), sampling_techniques.keys()], names=['Model', 'Sampling Technique'])\n",
    "df_performance = pd.DataFrame(index=index, columns=metrics)\n",
    "\n",
    "# Loop through each model and sampling technique, train, and evaluate\n",
    "for model_name, model in models.items():\n",
    "    for technique_name, technique in sampling_techniques.items():\n",
    "        # Apply sampling technique\n",
    "        X_resampled, y_resampled = technique.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_holdout)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        sensitivity, specificity, precision, recall, f1 = evaluate_model(y_holdout, y_pred)\n",
    "        \n",
    "        # Store the performance metrics\n",
    "        df_performance.loc[(model_name, technique_name), :] = sensitivity, specificity, precision, recall, f1\n",
    "\n",
    "# Display the performance DataFrame\n",
    "print(df_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "                                              Sensitivity  Specificity  \\\n",
      "Model                     Sampling Technique                             \n",
      "Logistic Regression       Oversampling           0.712934     0.919618   \n",
      "                          Undersampling          0.712934     0.918679   \n",
      "                          SMOTE                  0.712934     0.916884   \n",
      "Logistic Regression Lasso Oversampling           0.712934     0.919618   \n",
      "                          Undersampling          0.712934     0.919775   \n",
      "                          SMOTE                  0.712934     0.916848   \n",
      "Decision Trees            Oversampling           0.526814     0.998459   \n",
      "                          Undersampling          0.940063     0.946231   \n",
      "                          SMOTE                  0.716088     0.992811   \n",
      "\n",
      "                                              Precision    Recall  F1 Score  \n",
      "Model                     Sampling Technique                                 \n",
      "Logistic Regression       Oversampling         0.032749  0.712934  0.062621  \n",
      "                          Undersampling        0.032383  0.712934  0.061952  \n",
      "                          SMOTE                0.031706  0.712934  0.060712  \n",
      "Logistic Regression Lasso Oversampling         0.032749  0.712934  0.062621  \n",
      "                          Undersampling        0.032811  0.712934  0.062734  \n",
      "                          SMOTE                0.031693  0.712934  0.060687  \n",
      "Decision Trees            Oversampling         0.566102  0.526814  0.545752  \n",
      "                          Undersampling        0.062566  0.940063  0.117323  \n",
      "                          SMOTE                0.275485  0.716088  0.397897  \n",
      "\n",
      "Max Values by Sampling Technique:\n",
      "                    Sensitivity  Specificity  Precision    Recall  F1 Score\n",
      "Sampling Technique                                                         \n",
      "Oversampling           0.712934     0.998459   0.566102  0.712934  0.545752\n",
      "SMOTE                  0.716088     0.992811   0.275485  0.716088  0.397897\n",
      "Undersampling          0.940063     0.946231   0.062566  0.940063  0.117323\n",
      "\n",
      "Max Values by Model:\n",
      "                           Sensitivity  Specificity  Precision    Recall  \\\n",
      "Model                                                                      \n",
      "Decision Trees                0.940063     0.998459   0.566102  0.940063   \n",
      "Logistic Regression           0.712934     0.919618   0.032749  0.712934   \n",
      "Logistic Regression Lasso     0.712934     0.919775   0.032811  0.712934   \n",
      "\n",
      "                           F1 Score  \n",
      "Model                                \n",
      "Decision Trees             0.545752  \n",
      "Logistic Regression        0.062621  \n",
      "Logistic Regression Lasso  0.062734  \n"
     ]
    }
   ],
   "source": [
    "df_performance = df_performance.astype(float)\n",
    "\n",
    "# Calculate minimum values for each sampling technique across all models\n",
    "max_by_sampling = df_performance.groupby(level='Sampling Technique').max()\n",
    "\n",
    "# Calculate minimum values for each model across all sampling techniques\n",
    "max_by_model = df_performance.groupby(level='Model').max()\n",
    "\n",
    "# Display the performance DataFrame and minimum values\n",
    "print(\"Performance Metrics:\")\n",
    "print(df_performance)\n",
    "print(\"\\nMax Values by Sampling Technique:\")\n",
    "print(max_by_sampling)\n",
    "print(\"\\nMax Values by Model:\")\n",
    "print(max_by_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity (Recall): Decision Trees with Undersampling shows a remarkably high sensitivity, significantly outperforming other model-sampling combinations. High sensitivity is crucial if the cost of false negatives is high.\n",
    "\n",
    "Specificity: Decision Trees with Oversampling exhibits the highest specificity, which indicates its strength in correctly identifying the negatives. However, this comes with a trade-off in sensitivity.\n",
    "\n",
    "Precision: Decision Trees with Oversampling also has the highest precision, which means it has a lower false positive rate.\n",
    "\n",
    "F1 Score: The F1 Score balances the precision and recall, and we can see that Decision Trees with Oversampling have the highest F1 score, indicating a balanced performance between precision and recall.\n",
    "\n",
    "Given these observations, the Decision Trees with Oversampling seem to perform best overall based on the F1 Score, which is a harmonic mean of precision and recall. \n",
    "\n",
    "But there is not a resampling method that outperformance others when models change. SMOTE works better at  recall and sensitivity, oversampling works better at Specificity, precision and F-1 score, while undersampling works better at sensitivity and recall.\n",
    "\n",
    "All in all, I prefer the Decision Trees with Oversampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
